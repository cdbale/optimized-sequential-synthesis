{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4759687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "import time\n",
    "\n",
    "rng = default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78d23bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart_pmse_ratio(original_data, synthetic_data_sets):\n",
    "    \n",
    "    ### get pmse measures for synthetic data set pairs\n",
    "    \n",
    "    null_pmse_list = []\n",
    "    \n",
    "    inds = np.arange(len(synthetic_data_sets))\n",
    "    \n",
    "    combo_list = list(itertools.combinations(inds, 2))\n",
    "    \n",
    "    for combo in combo_list:\n",
    "    \n",
    "        s1 = synthetic_data_sets[combo[0]]\n",
    "        s2 = synthetic_data_sets[combo[1]]\n",
    "    \n",
    "        N_orig = s1.shape[0]\n",
    "        N_synth = s2.shape[0]\n",
    "    \n",
    "        c = N_synth/(N_synth+N_orig)\n",
    "    \n",
    "        full_X = pd.concat([s1, s2], axis=0).reset_index(drop=True)\n",
    "    \n",
    "        full_X = preprocessing.StandardScaler().fit_transform(full_X)\n",
    "\n",
    "        y = np.repeat([0, 1], repeats=[N_orig, N_synth])\n",
    "    \n",
    "        cart = DecisionTreeClassifier(min_samples_split=20,\n",
    "                                      min_samples_leaf=int(np.round(20/3)),\n",
    "                                      ccp_alpha=0.0001,\n",
    "                                      max_depth=30)\n",
    "    \n",
    "        cart.fit(X=full_X, y=y)\n",
    "    \n",
    "        probs = cart.predict_proba(full_X)\n",
    "    \n",
    "        pMSE = 1/(N_synth + N_orig) * np.sum((probs[:,1] - c)**2)\n",
    "        \n",
    "        null_pmse_list.append(pMSE)\n",
    "    \n",
    "    pmse_list = []\n",
    "    \n",
    "    for s in synthetic_data_sets:\n",
    "    \n",
    "        N_orig = original_data.shape[0]\n",
    "        N_synth = s.shape[0]\n",
    "    \n",
    "        c = N_synth/(N_synth+N_orig)\n",
    "    \n",
    "        full_X = pd.concat([original_data, s], axis=0).reset_index(drop=True)\n",
    "    \n",
    "        full_X = preprocessing.StandardScaler().fit_transform(full_X)\n",
    "\n",
    "        y = np.repeat([0, 1], repeats=[N_orig, N_synth])\n",
    "    \n",
    "        cart = DecisionTreeClassifier(min_samples_split=20,\n",
    "                                      min_samples_leaf=int(np.round(20/3)),\n",
    "                                      ccp_alpha=0.0001,\n",
    "                                      max_depth=30)\n",
    "    \n",
    "        cart.fit(X=full_X, y=y)\n",
    "    \n",
    "        probs = cart.predict_proba(full_X)\n",
    "    \n",
    "        pMSE = 1/(N_synth + N_orig) * np.sum((probs[:,1] - c)**2)\n",
    "        \n",
    "        pmse_list.append(pMSE)\n",
    "    \n",
    "    return np.array(pmse_list)/np.mean(null_pmse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03ba53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmse_ratio(original_data, synthetic_data):\n",
    "    \n",
    "    N_synth = synthetic_data.shape[0]\n",
    "    N_orig = original_data.shape[0]\n",
    "    \n",
    "    # combine original and synthetic datasets\n",
    "    full_X = pd.concat([original_data, synthetic_data], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # generate interactions and powers of variables\n",
    "    poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "    \n",
    "    full_X = poly.fit_transform(full_X)\n",
    "\n",
    "    # scale the combined dataset\n",
    "    full_X = preprocessing.StandardScaler().fit_transform(full_X)\n",
    "    \n",
    "    c = N_synth/(N_synth+N_orig)\n",
    "\n",
    "    y = np.repeat([0, 1], repeats=[N_orig, N_synth])\n",
    "    \n",
    "    pMSE_model = LogisticRegression(penalty='none', max_iter=1000).fit(full_X, y)\n",
    "    \n",
    "    probs = pMSE_model.predict_proba(full_X)\n",
    "    \n",
    "    pMSE = 1/(N_synth+N_orig) * np.sum((probs[:,1] - c)**2)\n",
    "    \n",
    "    e_pMSE = 2*(full_X.shape[1])*(1-c)**2 * c/(N_synth+N_orig)\n",
    "        \n",
    "    return pMSE/e_pMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b568349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def privacy_metrics(train_data, holdout_data, synthetic_data, delta):\n",
    "    \n",
    "    training_tree = KDTree(train_data)\n",
    "    \n",
    "    holdout_dists, holdout_neighbors = training_tree.query(x=holdout_data, k=5, p=2)\n",
    "    \n",
    "    synthetic_dists, synthetic_neighbors = training_tree.query(x=synthetic_data, k=5, p=2)\n",
    "    \n",
    "    IMS_holdout = np.mean(holdout_dists[:,0] <= delta)\n",
    "    \n",
    "    IMS_synthetic = np.mean(synthetic_dists[:,0] <= delta)\n",
    "    \n",
    "    DCR_holdout = np.percentile(holdout_dists[:,0], q=5)\n",
    "    \n",
    "    DCR_synthetic = np.percentile(synthetic_dists[:,0], q=5)\n",
    "    \n",
    "    ratios_synthetic = synthetic_dists[:,0]/synthetic_dists[:,-1]\n",
    "    \n",
    "    ratios_holdout = holdout_dists[:,0]/holdout_dists[:,-1]\n",
    "    \n",
    "    NNDR_synthetic = np.percentile(ratios_synthetic, q=5)\n",
    "    \n",
    "    NNDR_holdout = np.percentile(ratios_holdout, q=5)\n",
    "    \n",
    "    ### share calculation\n",
    "    \n",
    "    # distance between synthetic and holdout \n",
    "    holdout_tree = KDTree(holdout_data)\n",
    "    \n",
    "    trn_dists, _ = training_tree.query(x=synthetic_data, k=1, p=2)\n",
    "    hld_dists, _ = holdout_tree.query(x=synthetic_data, k=1, p=2)\n",
    "    \n",
    "    closer_syn = np.mean(trn_dists < hld_dists) + (train_data.shape[0]/(train_data.shape[0]+holdout_data.shape[0])) * np.mean(trn_dists == hld_dists)\n",
    "    \n",
    "    return ({\"IMS_holdout\": IMS_holdout, \"IMS_synthetic\": IMS_synthetic,\n",
    "             \"DCR_holdout\": DCR_holdout, \"DCR_synthetic\": DCR_synthetic,\n",
    "             \"NNDR_holdout\": NNDR_holdout, \"NNDR_synthetic\": NNDR_synthetic,\n",
    "             \"Share Closer Train\": closer_syn})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0340e44",
   "metadata": {},
   "source": [
    "# Simulation 1: Privacy Metrics When Data Come From The Same Sampling Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d996a",
   "metadata": {},
   "source": [
    "Structure simulation the same way as Snoke et al. 2018. \n",
    "\n",
    "* 1000 simulations\n",
    "* For each simulation\n",
    "    * generate 10 data sets, each of size $N = 5000$\n",
    "        * each data is multivariate normal with $\\mu = 0$ and $\\sigma^2 = 1$ with covariances equal to 0, 0.1, ..., 0.9 for each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3950e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def privacy_simulation(sample_size, covariance_values, nreps):\n",
    "    \n",
    "    m = np.zeros((10))\n",
    "    diag = np.repeat(1.0, 10)\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    for v in covariance_values:\n",
    "        \n",
    "        covmat = np.zeros((10, 10))\n",
    "        covmat[:,:] = v\n",
    "        np.fill_diagonal(covmat, diag)\n",
    "        \n",
    "        results_dict[str(v)] = []\n",
    "        \n",
    "        for r in range(nreps):\n",
    "        \n",
    "            training = pd.DataFrame(rng.multivariate_normal(mean=m, cov=covmat, size=sample_size))\n",
    "            holdout = [pd.DataFrame(rng.multivariate_normal(mean=m, cov=covmat, size=sample_size)) for i in range(10)]\n",
    "            synthetic = [pd.DataFrame(rng.multivariate_normal(mean=m, cov=covmat, size=sample_size)) for i in range(10)]\n",
    "            \n",
    "            metrics = privacy_metrics(training, holdout[0], synthetic[0], delta=1)\n",
    "            \n",
    "            metrics['pmse_th'] = pmse_ratio(training, holdout[0])\n",
    "            metrics['pmse_ts'] = pmse_ratio(training, synthetic[0])\n",
    "            metrics['pmse_hs'] = pmse_ratio(holdout[0], synthetic[0])\n",
    "            \n",
    "            metrics['cart_pmse_th'] = cart_pmse_ratio(training, holdout)\n",
    "            metrics['cart_pmse_ts'] = cart_pmse_ratio(training, synthetic)\n",
    "            metrics['cart_pmse_hs'] = cart_pmse_ratio(holdout[0], synthetic)\n",
    "            \n",
    "            results_dict[str(v)].append(metrics)\n",
    "            \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77f1bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 100\n",
    "sample_size = 5000\n",
    "cov_vals = np.linspace(start=0.0, stop=0.9, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d7eb0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 515.9475 minutes\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "privacy_results = privacy_simulation(sample_size=sample_size, covariance_values=cov_vals, nreps=reps)\n",
    "toc = time.perf_counter()\n",
    "print(f\"Completed in {(toc - tic)/60:0.4f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc4cbe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 5.2154 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Completed in {(toc - tic)/60:0.4f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40e71164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of Mean Holdout IMS to Mean Synthetic IMS for Each Covariance Value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.00842498, 1.0002244 , 1.00879434, 0.99847384, 0.99611855,\n",
       "       0.99706426, 0.99968814, 1.00174039, 1.00019728, 0.99968218])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Ratio of Mean Holdout IMS to Mean Synthetic IMS for Each Covariance Value\")\n",
    "np.array([np.mean([x['IMS_holdout'] for x in privacy_results[str(i)]]) for i in cov_vals])/[np.mean([x['IMS_synthetic'] for x in privacy_results[str(i)]]) for i in cov_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64d8c12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of Mean Holdout DCR to Mean Synthetic DCR for Each Covariance Value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99812798, 1.00019294, 0.99901501, 1.00062875, 1.00066774,\n",
       "       1.00060701, 0.99898692, 0.99849151, 0.99863952, 1.00131152])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Ratio of Mean Holdout DCR to Mean Synthetic DCR for Each Covariance Value\")\n",
    "np.array([np.mean([x['DCR_holdout'] for x in privacy_results[str(i)]]) for i in cov_vals])/np.array([np.mean([x['DCR_synthetic'] for x in privacy_results[str(i)]]) for i in cov_vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6f7888f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of Mean Holdout NNDR to Mean Synthetic DCR for Each Covariance Value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99866955, 1.00103444, 0.99861143, 0.99926913, 1.00109817,\n",
       "       0.99959567, 0.99914713, 0.99860656, 0.99927854, 1.00118629])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Ratio of Mean Holdout NNDR to Mean Synthetic DCR for Each Covariance Value\")\n",
    "np.array([np.mean([x['NNDR_holdout'] for x in privacy_results[str(i)]]) for i in cov_vals])/np.array([np.mean([x['NNDR_synthetic'] for x in privacy_results[str(i)]]) for i in cov_vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b216b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean pMSE Ratio for Training vs. Holdout\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.021794951340699,\n",
       " 0.9611643718916993,\n",
       " 1.0020765906925302,\n",
       " 0.9753561627020999,\n",
       " 1.0250464073469683,\n",
       " 1.001985670646797,\n",
       " 1.0274314530830706,\n",
       " 1.0143000820138628,\n",
       " 1.0286703490698246,\n",
       " 1.0088222923133487]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mean pMSE Ratio for Training vs. Holdout\")\n",
    "[np.mean([x['pmse_th'] for x in privacy_results[str(i)]]) for i in cov_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e4f51a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean pMSE Ratio for Training vs. Synthetic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9755757746995183,\n",
       " 0.9742822937106407,\n",
       " 1.0122815334095276,\n",
       " 0.9946327227077195,\n",
       " 1.0196226761542337,\n",
       " 1.0044254635234113,\n",
       " 0.9935973556040235,\n",
       " 1.0037880074701937,\n",
       " 0.992979016150962,\n",
       " 0.9928120047801562]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mean pMSE Ratio for Training vs. Synthetic\")\n",
    "[np.mean([x['pmse_ts'] for x in privacy_results[str(i)]]) for i in cov_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09ef8545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean pMSE Ratio for Holdout vs. Synthetic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9669063778458379,\n",
       " 1.0058026172031715,\n",
       " 0.9783201986052351,\n",
       " 1.0037883243117387,\n",
       " 1.0088287594068903,\n",
       " 0.9974754412246799,\n",
       " 1.002802581781001,\n",
       " 0.9602034251685626,\n",
       " 1.0028266280425011,\n",
       " 1.0000617806184948]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mean pMSE Ratio for Holdout vs. Synthetic\")\n",
    "[np.mean([x['pmse_hs'] for x in privacy_results[str(i)]]) for i in cov_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fe7a794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CART pMSE Ratio for Training vs. Holdout\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9971905223517445,\n",
       " 1.0005184458465375,\n",
       " 1.007218424915615,\n",
       " 1.0067930184103588,\n",
       " 0.9975248182937658,\n",
       " 1.0039396679180812,\n",
       " 0.9992660199578481,\n",
       " 0.9970495256828041,\n",
       " 0.9941106167069336,\n",
       " 1.0003347134865082]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mean CART pMSE Ratio for Training vs. Holdout\")\n",
    "[np.mean([x['cart_pmse_th'] for x in privacy_results[str(i)]]) for i in cov_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff743dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CART pMSE Ratio for Training vs. Synthetic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0002019840638685,\n",
       " 0.9971987520016865,\n",
       " 1.0029586484866901,\n",
       " 1.000903979174189,\n",
       " 0.9991779188067469,\n",
       " 1.0032604367054823,\n",
       " 1.0038372089513192,\n",
       " 1.0007655154507895,\n",
       " 0.9829518038550807,\n",
       " 0.9962852377475268]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mean CART pMSE Ratio for Training vs. Synthetic\")\n",
    "[np.mean([x['cart_pmse_ts'] for x in privacy_results[str(i)]]) for i in cov_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4caf9de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CART pMSE Ratio for Holdout vs. Synthetic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9935539722683945,\n",
       " 0.9940674448846606,\n",
       " 0.9995756981138811,\n",
       " 0.9979176368546354,\n",
       " 1.011564346312473,\n",
       " 1.0128866240759833,\n",
       " 1.0096695339950932,\n",
       " 0.9919765014969996,\n",
       " 1.0000368666105877,\n",
       " 1.0022959563714158]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mean CART pMSE Ratio for Holdout vs. Synthetic\")\n",
    "[np.mean([x['cart_pmse_hs'] for x in privacy_results[str(i)]]) for i in cov_vals]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04910dfd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d92b5",
   "metadata": {},
   "source": [
    "### Simulation 2: Test Whether Bayesian Optimization Can Recover the Correct Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9223d06f",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "* sample data from normal distribution - call it train\n",
    "* use bayesian optimization to choose mean and covariance parameters, using geometric mean of expected pmse ratio as objective\n",
    "* check whether bayesian optimization found the correct parameters, and what the resulting pmse ratio is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e80fdf",
   "metadata": {},
   "source": [
    "The first simulation has mean $(0, 0)$ and diagonal covariance matrix with variances of $(1, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b1f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesis_model(train_data, number_synthetic_datasets, m1_, m2_, v1_, v2_):\n",
    "    \n",
    "    # number of samples to draw\n",
    "    num_samples = train_data.shape[0]\n",
    "    \n",
    "    mean_vec = np.array([m1_, m2_])\n",
    "    covariance_mat = np.zeros((2, 2))\n",
    "    covmat_diag = np.array([v1_, v2_])\n",
    "    np.fill_diagonal(covariance_mat, covmat_diag)\n",
    "    \n",
    "    sXs = [pd.DataFrame(rng.multivariate_normal(mean=mean_vec, cov=covariance_mat, size=num_samples)) for i in range(number_synthetic_datasets)]\n",
    "        \n",
    "    ###### Calculate pMSE ratios ######\n",
    "    pmse_ratios = [pmse_ratio(train_data, Y) for Y in sXs]\n",
    "    \n",
    "    return pmse_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c3ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_synthesis(train_data, number_synthetic_datasets):\n",
    "\n",
    "    def evaluate_model(m1_, m2_, v1_, v2_):\n",
    "\n",
    "        pmse_ratios = synthesis_model(train_data=train_data,\n",
    "                                      number_synthetic_datasets=number_synthetic_datasets,\n",
    "                                      m1_=m1_,\n",
    "                                      m2_=m2_,\n",
    "                                      v1_=v1_,\n",
    "                                      v2_=v2_)\n",
    "\n",
    "        return -np.mean([(1 - x)**2 for x in pmse_ratios])\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=evaluate_model,\n",
    "        pbounds={\n",
    "            \"m1_\": (-1, 1),\n",
    "            \"m2_\": (-1, 1),\n",
    "            \"v1_\": (0.9, 1.1),\n",
    "            \"v2_\": (0.9, 1.1)\n",
    "        })\n",
    "\n",
    "    optimizer.maximize(acq='ei', xi=1e-2, n_iter=50)\n",
    "    print(\"Final Result: \", optimizer.max)\n",
    "    return optimizer.max, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a1be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 20\n",
    "\n",
    "m = np.zeros((2))\n",
    "covmat = np.zeros((2, 2))\n",
    "diag = np.repeat(1.0, 2)\n",
    "np.fill_diagonal(covmat, diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.DataFrame(rng.multivariate_normal(mean=m, cov=covmat, size=sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_results = [optimize_synthesis(train_data=sample, number_synthetic_datasets=M) for r in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_targets = [np.minimum.accumulate(-i[1].space.target) for i in optimization_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(run_targets[0])\n",
    "plt.scatter(np.arange(len(run_targets[0])), run_targets[0], s=6)\n",
    "plt.plot(run_targets[1])\n",
    "plt.scatter(np.arange(len(run_targets[1])), run_targets[1], s=6)\n",
    "plt.plot(run_targets[2])\n",
    "plt.scatter(np.arange(len(run_targets[2])), run_targets[2], s=6)\n",
    "plt.plot(run_targets[3])\n",
    "plt.scatter(np.arange(len(run_targets[3])), run_targets[3], s=6)\n",
    "plt.plot(run_targets[4])\n",
    "plt.scatter(np.arange(len(run_targets[4])), run_targets[4], s=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8843e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = optimization_results[np.argmax([x[0]['target'] for x in optimization_results])][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf49f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = synthesis_model(train_data=sample,\n",
    "                         number_synthetic_datasets=100,\n",
    "                         m1_=best_params['params']['m1_'],\n",
    "                         m2_=best_params['params']['m2_'],\n",
    "                         v1_=best_params['params']['v1_'],\n",
    "                         v2_=best_params['params']['v2_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803396e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratios = synthesis_model(train_data=sample,\n",
    "#                          number_synthetic_datasets=100,\n",
    "#                          m1_=0.0,\n",
    "#                          m2_=0.0,\n",
    "#                          v1_=1.0,\n",
    "#                          v2_=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5516d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258934e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
