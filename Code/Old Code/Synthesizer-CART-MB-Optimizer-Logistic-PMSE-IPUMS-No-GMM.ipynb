{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f48262",
   "metadata": {},
   "source": [
    "This notebook performs the synthesis using our proposed synthesization approach for the training data only (excludes the holdout data). The synthesis model is a CART."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.spatial import cKDTree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from bayesian_bootstrap import bayesian_bootstrap\n",
    "\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57505dd1",
   "metadata": {},
   "source": [
    "Steps for CART estimation of pmse ratio.\n",
    "\n",
    "* calculate the pMSE between pairs of synthetic data sets generated from the same original data\n",
    "* the pairs can be used to estimate the expected pMSE even when the synthesizing model is incorrect since both data are drawn from the same distribution\n",
    "* for most large complex data sets, synthesized by CART models, the expected pMSE from pairs will be close to, or slightly lower than the null pMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ad9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmse_ratio(original_data, synthetic_data):\n",
    "    \n",
    "    N_synth = synthetic_data.shape[0]\n",
    "    N_orig = original_data.shape[0]\n",
    "    \n",
    "    # combine original and synthetic datasets\n",
    "    full_X = pd.concat([original_data, synthetic_data], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # generate interactions and powers of variables\n",
    "    poly = PolynomialFeatures(3, interaction_only=False, include_bias=False)\n",
    "    \n",
    "    full_X = poly.fit_transform(full_X)\n",
    "\n",
    "    # scale the combined dataset\n",
    "    full_X = preprocessing.StandardScaler().fit_transform(full_X)\n",
    "    \n",
    "    c = N_synth/(N_synth+N_orig)\n",
    "\n",
    "    y = np.repeat([0, 1], repeats=[N_orig, N_synth])\n",
    "    \n",
    "    pMSE_model = LogisticRegression(penalty=None, max_iter=1000).fit(full_X, y)\n",
    "    \n",
    "    probs = pMSE_model.predict_proba(full_X)\n",
    "    \n",
    "    pMSE = 1/(N_synth+N_orig) * np.sum((probs[:,1] - c)**2)\n",
    "    \n",
    "    e_pMSE = 2*(full_X.shape[1])*(1-c)**2 * c/(N_synth+N_orig)\n",
    "        \n",
    "    return pMSE/e_pMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8ccbc",
   "metadata": {},
   "source": [
    "Import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standardized lat/long location data\n",
    "train_data = pd.read_csv(\"Data/cleaned_ipums_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62abff",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb46ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7801efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_data.non_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_data.SEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343dbc70",
   "metadata": {},
   "source": [
    "Let's start the synthesis with sampling from the joint distribution of `non_white` and `SEX`. Then use CART to synthesize the three continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35a00d",
   "metadata": {},
   "source": [
    "Write a function to estimate the joint distribution and sample from it. Will be used in the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bea34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_sample(training_data):\n",
    "    \n",
    "    # probability for each combination of values\n",
    "    pvals = (pd.crosstab(train_data.non_white, train_data.SEX)/train_data.shape[0]).values.flatten()\n",
    "    \n",
    "    # sample from multinomial distribution - how many occurrences of each 'class'\n",
    "    new_counts = rng.multinomial(n=train_data.shape[0], pvals=pvals)\n",
    "    \n",
    "    # create a data frame with the new samples\n",
    "    new_data = pd.DataFrame(np.vstack([np.repeat([['0', '0']], new_counts[0], axis=0),\n",
    "           np.repeat([['0', '1']], new_counts[1], axis=0),\n",
    "           np.repeat([['1', '0']], new_counts[2], axis=0),\n",
    "           np.repeat([['1', '1']], new_counts[3], axis=0)]))\n",
    "    \n",
    "    cols = new_data.columns.values\n",
    "    \n",
    "    new_data[cols] = new_data[cols].apply(pd.to_numeric)\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab35c8a8",
   "metadata": {},
   "source": [
    "Test the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de685f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8a741f",
   "metadata": {},
   "source": [
    "# Full Sequential Synthesis Driven by Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169fec7",
   "metadata": {},
   "source": [
    "Function to be used in Bayesian bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80a8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d67e56",
   "metadata": {},
   "source": [
    "Function for training a CART model on a continuous variable. Should be the same as for a categorical variable but with the additional step of estimating a kernel density and sampling new values from that density."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf781f7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee64381",
   "metadata": {},
   "source": [
    "Test the kernel density estimate and sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc4012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for synthetic datasets\n",
    "sXs = []\n",
    "    \n",
    "# generate and store number_synthetic_datasets synthetic datasets\n",
    "for i in range(3):\n",
    "    sX = categorical_sample(train_data)\n",
    "    sX.columns = ['non_white', 'SEX']\n",
    "    sXs.append(sX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3037fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_synthetic_datasets = sXs\n",
    "number_synthetic_datasets = 3 \n",
    "mb=5\n",
    "covariate_array = ['non_white', 'SEX']\n",
    "target = 'INCWAGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeRegressor(min_samples_leaf=mb, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a24adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart.fit(X=train_data.loc[:, covariate_array], y=train_data.loc[:, target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fb3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_indicators = cart.decision_path(train_data.loc[:, covariate_array]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_outcomes = [train_data[target][node_indicators[:,x] == 1] for x in np.arange(node_indicators.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ed408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample values according to a Bayesian bootstrap\n",
    "bst_vals = [bayesian_bootstrap(X=np.array(x), \n",
    "                               statistic=stat,\n",
    "                               n_replications=1,\n",
    "                               resample_size=len(x))[0] for x in node_outcomes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e229025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute which leaf each sensitive data record ends up in\n",
    "synth_leaves = cart.apply(current_synthetic_datasets[i].loc[:, covariate_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72734c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var = np.zeros(len(synth_leaves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd94bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5fe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(node_indicators.shape[1]):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = KernelDensity(kernel='gaussian', bandwidth=\"scott\").fit(bst_vals[2].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9193ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dens = kde.score_samples(np.linspace(-2, 4, 100)[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(-2, 4, 100)[:, np.newaxis], np.exp(log_dens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d3e50",
   "metadata": {},
   "source": [
    "Now generate some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be386b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1914af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d1165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vals = kde.sample(np.sum(synth_leaves==2)).flatten()\n",
    "to_replace = np.any([sample_vals < np.min(bst_vals[2]), sample_vals > np.max(bst_vals[2])], axis=0)\n",
    "while np.sum(to_replace) > 0:\n",
    "    sample_vals[to_replace] = kde.sample(np.sum(to_replace)).flatten()\n",
    "    to_replace = np.any([sample_vals < np.min(bst_vals[2]), sample_vals > np.max(bst_vals[2])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1246e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, x in enumerate(np.arange(node_indicators.shape[1])):\n",
    "    new_var[synth_leaves==x] = KernelDensity(kernel='gaussian', bandwidth=\"scott\").fit(bst_vals[x].reshape(-1,1)).sample(np.sum(synth_leaves==x)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db0cd5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_cart_synthesis(current_synthetic_datasets, train_data, number_synthetic_datasets, mb, covariate_array, target):\n",
    "        \n",
    "    cart = DecisionTreeRegressor(min_samples_leaf=mb, random_state=rng)\n",
    "    \n",
    "    cart.fit(X=train_data.loc[:, covariate_array], y=train_data.loc[:, target])\n",
    "    \n",
    "    node_indicators = cart.decision_path(train_data.loc[:, covariate_array]).toarray()\n",
    "    \n",
    "    node_outcomes = [train_data[target][node_indicators[:,x] == 1] for x in np.arange(node_indicators.shape[1])]\n",
    "    \n",
    "    for i in range(number_synthetic_datasets):\n",
    "        \n",
    "        # resample values according to a Bayesian bootstrap\n",
    "        bst_vals = [bayesian_bootstrap(X=np.array(x), \n",
    "                                       statistic=stat,\n",
    "                                       n_replications=1,\n",
    "                                       resample_size=len(x))[0] for x in node_outcomes]\n",
    "    \n",
    "        # compute which leaf each synthetic data record ends up in\n",
    "        synth_leaves = cart.apply(current_synthetic_datasets[i].loc[:, covariate_array])\n",
    "    \n",
    "        new_var = np.zeros(len(synth_leaves))\n",
    "    \n",
    "        for j, x in enumerate(np.arange(node_indicators.shape[1])):\n",
    "            \n",
    "            kde = KernelDensity(kernel='gaussian', bandwidth=\"scott\").fit(bst_vals[x].reshape(-1,1))\n",
    "            \n",
    "            sample_vals = kde.sample(np.sum(synth_leaves==x)).flatten()\n",
    "            to_replace = np.any([sample_vals < np.min(bst_vals[x]), sample_vals > np.max(bst_vals[x])], axis=0)\n",
    "            while np.sum(to_replace) > 0:\n",
    "                sample_vals[to_replace] = kde.sample(np.sum(to_replace)).flatten()\n",
    "                to_replace = np.any([sample_vals < np.min(bst_vals[x]), sample_vals > np.max(bst_vals[x])], axis=0)\n",
    "            \n",
    "            new_var[synth_leaves==x] = sample_vals\n",
    "        \n",
    "        new_var = pd.Series(new_var)\n",
    "        \n",
    "        new_var.name = target\n",
    "        \n",
    "        current_synthetic_datasets[i] = pd.concat([current_synthetic_datasets[i], new_var], axis=1)\n",
    "        \n",
    "    return current_synthetic_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e6d496",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1688b8",
   "metadata": {},
   "source": [
    "Write function to train all models and generate the synthetic dataset, then evaluate the pMSE ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(#overall parameters\n",
    "                 train_data,\n",
    "                 number_synthetic_datasets,\n",
    "                 # hyperparameters for GMM, end with underscore means Bayesian optimization will choose\n",
    "                 # number_gmm_initializations,\n",
    "                 # num_components_,\n",
    "                 # hyperparameters for CART, end with underscore means Bayesian optimization will choose\n",
    "                 mb_INCWAGE_,\n",
    "                 mb_educ_,\n",
    "                 mb_exp_):\n",
    "    \n",
    "    num_samples = train_data.shape[0]\n",
    "    \n",
    "    ########## Code for GMM ############\n",
    "    \n",
    "    # fit GMM model\n",
    "    # GMM = GaussianMixture(num_components_, n_init=number_gmm_initializations, init_params=\"k-means++\", random_state=rng).fit(train_data.loc[:,[\"latitude\", \"longitude\"]])\n",
    "    \n",
    "    # list for synthetic datasets\n",
    "    sXs = []\n",
    "    \n",
    "    # generate and store number_synthetic_datasets synthetic datasets\n",
    "    for i in range(number_synthetic_datasets):\n",
    "        sX = categorical_sample(train_data)\n",
    "        sX.columns = ['non_white', 'SEX']\n",
    "        sXs.append(sX)\n",
    "        \n",
    "    ####################################################################################################\n",
    "        \n",
    "    ########### Code for INCWAGE ##########\n",
    "    \n",
    "    sXs = continuous_cart_synthesis(current_synthetic_datasets=sXs,\n",
    "                                    train_data=train_data,\n",
    "                                    number_synthetic_datasets=number_synthetic_datasets,\n",
    "                                    mb=mb_INCWAGE_,\n",
    "                                    covariate_array=['non_white', 'SEX'],\n",
    "                                    target=\"INCWAGE\")\n",
    "        \n",
    "    ####################################################################################################\n",
    "        \n",
    "    ########### Code for years_of_educ CART ##########\n",
    "    sXs = continuous_cart_synthesis(current_synthetic_datasets=sXs,\n",
    "                                    train_data=train_data,\n",
    "                                    number_synthetic_datasets=number_synthetic_datasets,\n",
    "                                    mb=mb_educ_,\n",
    "                                    covariate_array=['non_white', 'SEX', 'INCWAGE'],\n",
    "                                    target=\"years_of_educ\")\n",
    "        \n",
    "    ####################################################################################################\n",
    "    \n",
    "    ########### Code for potential_experience CART ##########\n",
    "    \n",
    "    sXs = continuous_cart_synthesis(current_synthetic_datasets=sXs,\n",
    "                                    train_data=train_data,\n",
    "                                    number_synthetic_datasets=number_synthetic_datasets,\n",
    "                                    mb=mb_exp_,\n",
    "                                    covariate_array=['non_white', 'SEX', 'INCWAGE', 'years_of_educ'],\n",
    "                                    target=\"potential_experience\")\n",
    "    \n",
    "    sXs = [x.loc[:,list(train_data.columns.values)] for x in sXs]\n",
    "    \n",
    "    ###### Calculate ks distances ######\n",
    "    pmse_ratios = [pmse_ratio(train_data, Y) for Y in sXs]\n",
    "    \n",
    "    return pmse_ratios, sXs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796d2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_models(train_data,\n",
    "                    number_synthetic_datasets,\n",
    "                    # number_gmm_initializations,\n",
    "                    random_state):\n",
    "\n",
    "    def evaluate_models(mb_INCWAGE_, mb_educ_, mb_exp_):\n",
    "\n",
    "        pmse_ratios, _ = train_models(train_data=train_data,\n",
    "                                      number_synthetic_datasets=number_synthetic_datasets,\n",
    "                                      # number_gmm_initializations=number_gmm_initializations,\n",
    "                                      # num_components_=int(num_components_),\n",
    "                                      mb_INCWAGE_=int(mb_INCWAGE_),\n",
    "                                      mb_educ_=int(mb_educ_),\n",
    "                                      mb_exp_=int(mb_exp_))\n",
    "\n",
    "        return -1 * ((1 - np.mean(pmse_ratios))**2)\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=evaluate_models,\n",
    "        pbounds={\n",
    "            # \"num_components_\": (200, 800.99),\n",
    "            \"mb_INCWAGE_\": (3, 300.99),\n",
    "            \"mb_educ_\": (3, 300.99),\n",
    "            \"mb_exp_\": (3, 300.99)\n",
    "        },\n",
    "        random_state=random_state)\n",
    "\n",
    "    utility = UtilityFunction(kind=\"ei\", xi=1e-02)\n",
    "    optimizer.maximize(init_points=5, n_iter=10, acquisition_function=utility)\n",
    "    print(\"Final Result: \", optimizer.max)\n",
    "    return optimizer.max, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5594760a",
   "metadata": {},
   "source": [
    "The default value of $\\alpha = 1e-06$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d5ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd = 5\n",
    "# ngi = 5\n",
    "# random_states = [np.random.RandomState(1234), np.random.RandomState(4321), np.random.RandomState(10620), np.random.RandomState(91695), np.random.RandomState(31296)]\n",
    "random_states = [np.random.RandomState(1234)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_results = [optimize_models(train_data=train_data, number_synthetic_datasets=nsd, random_state=r) for r in random_states]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab452a9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c71552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_targets = [np.minimum.accumulate(-i[1].space.target) for i in optimization_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2e246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(run_targets[0])\n",
    "plt.scatter(np.arange(len(run_targets[0])), run_targets[0], s=6)\n",
    "plt.plot(run_targets[1])\n",
    "plt.scatter(np.arange(len(run_targets[1])), run_targets[1], s=6)\n",
    "plt.plot(run_targets[2])\n",
    "plt.scatter(np.arange(len(run_targets[2])), run_targets[2], s=6)\n",
    "plt.plot(run_targets[3])\n",
    "plt.scatter(np.arange(len(run_targets[3])), run_targets[3], s=6)\n",
    "plt.plot(run_targets[4])\n",
    "plt.scatter(np.arange(len(run_targets[4])), run_targets[4], s=6)\n",
    "plt.title(\"Running Minimum Objective Value for CART Synthesis\")\n",
    "plt.ylim(-0.01, 0.47)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325348ce",
   "metadata": {},
   "source": [
    "Choose the params that gave the best objective value across all random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f179aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = optimization_results[np.argmax([x[0]['target'] for x in optimization_results])][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b4969",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c940983",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e1ea09",
   "metadata": {},
   "source": [
    "Generate 1000 synthetic datasets, choose the 20 that have the pMSE closest to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed0391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmse_ratios, full_sXs = train_models(train_data=train_data,\n",
    "                                                                          number_synthetic_datasets=nsd,\n",
    "                                                                          # hyperparameters for GMM\n",
    "                                                                          # number_gmm_initializations=ngi,\n",
    "                                                                          # num_components_=int(best_params['params']['num_components_']),\n",
    "                                                                          # hyperparameters for CART, end with underscore means Bayesian optimization will choose\n",
    "                                                                          mb_INCWAGE_=int(best_params['params']['mb_INCWAGE_']),\n",
    "                                                                          mb_educ_=int(best_params['params']['mb_educ_']),\n",
    "                                                                          mb_exp_=int(best_params['params']['mb_exp_']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pmse_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.violinplot(pmse_ratios)\n",
    "plt.xlabel(\"Density\")\n",
    "plt.ylabel(\"pMSE Ratio\")\n",
    "plt.title(\"Distribution of pMSE Ratios\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = full_sXs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c57345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8575f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(temp.non_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9581c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_data.non_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(train_data.non_white, train_data.SEX)/train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8092486",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(temp.non_white, temp.SEX)/temp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(temp.potential_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_data.potential_experience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d77671",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52024190",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = temp\n",
    "original_data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bdcc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_synth = synthetic_data.shape[0]\n",
    "N_orig = original_data.shape[0]\n",
    "    \n",
    "# combine original and synthetic datasets\n",
    "full_X = pd.concat([original_data, synthetic_data], axis=0).reset_index(drop=True)\n",
    "    \n",
    "# generate interactions and powers of variables\n",
    "poly = PolynomialFeatures(1, interaction_only=False, include_bias=False)\n",
    "    \n",
    "full_X = poly.fit_transform(full_X)\n",
    "\n",
    "# scale the combined dataset\n",
    "full_X = preprocessing.StandardScaler().fit_transform(full_X)\n",
    "    \n",
    "c = N_synth/(N_synth+N_orig)\n",
    "\n",
    "y = np.repeat([0, 1], repeats=[N_orig, N_synth])\n",
    "    \n",
    "pMSE_model = LogisticRegression(penalty=None, max_iter=1000).fit(full_X, y)\n",
    "    \n",
    "probs = pMSE_model.predict_proba(full_X)\n",
    "    \n",
    "pMSE = 1/(N_synth+N_orig) * np.sum((probs[:,1] - c)**2)\n",
    "    \n",
    "e_pMSE = 2*(full_X.shape[1])*(1-c)**2 * c/(N_synth+N_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e64df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMSE/e_pMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMSE_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c290bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51297e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from statsmodels.tools.tools import add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_sm = add_constant(full_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8622e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9176a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = Logit(endog = y,\n",
    "           exog = full_X_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = lm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b332a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af137729",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c4b464",
   "metadata": {},
   "source": [
    "# Save the synthetic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5696e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sX in enumerate(full_sXs):\n",
    "    sX.to_csv(\"Data/synthetic_datasets/cart_mb_logistic_pmse_\" + str(i) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40ffaea",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
