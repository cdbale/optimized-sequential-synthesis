{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Assessing Privacy Risk Using the Attack from Ponte et al. (2024)\n",
    "\n",
    "https://github.com/GilianPonte/whereswaldoIJRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "%matplotlib inline\n",
    "\n",
    "# Add the parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Then import\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the oversampled subset of the Criteo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../../Data/Criteo/cleaned_criteo_os.gz\",\n",
    "                         compression='gzip', \n",
    "                         sep='\\,',\n",
    "                         header=0,\n",
    "                         engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicates and reset index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>treatment</th>\n",
       "      <th>conversion</th>\n",
       "      <th>visit</th>\n",
       "      <th>exposure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.616365</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.928801</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>0.294443</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.955396</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.616365</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>9.038744</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>0.294443</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.955396</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.616365</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.322806</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>0.294443</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.906514</td>\n",
       "      <td>25.240993</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.385197</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.214383</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-3.993764</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.971858</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.293259</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.214383</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-3.993764</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.971858</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447157</th>\n",
       "      <td>13.680284</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.325934</td>\n",
       "      <td>-0.600592</td>\n",
       "      <td>11.029584</td>\n",
       "      <td>1.128518</td>\n",
       "      <td>-13.045950</td>\n",
       "      <td>10.885556</td>\n",
       "      <td>3.758296</td>\n",
       "      <td>44.784329</td>\n",
       "      <td>5.844038</td>\n",
       "      <td>-0.267350</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447158</th>\n",
       "      <td>14.251906</td>\n",
       "      <td>13.579750</td>\n",
       "      <td>8.303577</td>\n",
       "      <td>-2.272900</td>\n",
       "      <td>12.594889</td>\n",
       "      <td>-4.636110</td>\n",
       "      <td>-19.328059</td>\n",
       "      <td>5.621479</td>\n",
       "      <td>3.755250</td>\n",
       "      <td>42.018683</td>\n",
       "      <td>6.141586</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447159</th>\n",
       "      <td>20.711370</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.290111</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-6.359690</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.813849</td>\n",
       "      <td>26.606156</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447160</th>\n",
       "      <td>23.767207</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.283185</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-3.282109</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.767224</td>\n",
       "      <td>46.714867</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447161</th>\n",
       "      <td>23.752643</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.306093</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-15.877431</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.803969</td>\n",
       "      <td>40.811160</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>447162 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               f0         f1        f2        f3         f4        f5  \\\n",
       "0       12.616365  10.059654  8.928801  4.679882  10.280525  4.115453   \n",
       "1       12.616365  10.059654  9.038744  4.679882  10.280525  4.115453   \n",
       "2       12.616365  10.059654  8.322806  4.679882  10.280525  4.115453   \n",
       "3       25.385197  10.059654  8.214383  4.679882  10.280525  4.115453   \n",
       "4       22.293259  10.059654  8.214383  4.679882  10.280525  4.115453   \n",
       "...           ...        ...       ...       ...        ...       ...   \n",
       "447157  13.680284  10.059654  8.325934 -0.600592  11.029584  1.128518   \n",
       "447158  14.251906  13.579750  8.303577 -2.272900  12.594889 -4.636110   \n",
       "447159  20.711370  10.059654  8.290111  4.679882  10.280525  4.115453   \n",
       "447160  23.767207  10.059654  8.283185  4.679882  10.280525  4.115453   \n",
       "447161  23.752643  10.059654  8.306093  4.679882  10.280525  4.115453   \n",
       "\n",
       "               f6         f7        f8         f9       f10       f11  \\\n",
       "0        0.294443   4.833815  3.955396  13.190056  5.300375 -0.168679   \n",
       "1        0.294443   4.833815  3.955396  13.190056  5.300375 -0.168679   \n",
       "2        0.294443   4.833815  3.906514  25.240993  5.300375 -0.168679   \n",
       "3       -3.993764   4.833815  3.971858  13.190056  5.300375 -0.168679   \n",
       "4       -3.993764   4.833815  3.971858  13.190056  5.300375 -0.168679   \n",
       "...           ...        ...       ...        ...       ...       ...   \n",
       "447157 -13.045950  10.885556  3.758296  44.784329  5.844038 -0.267350   \n",
       "447158 -19.328059   5.621479  3.755250  42.018683  6.141586 -0.168679   \n",
       "447159  -6.359690   4.833815  3.813849  26.606156  5.300375 -0.168679   \n",
       "447160  -3.282109   4.833815  3.767224  46.714867  5.300375 -0.168679   \n",
       "447161 -15.877431   4.833815  3.803969  40.811160  5.300375 -0.168679   \n",
       "\n",
       "        treatment  conversion  visit  exposure  \n",
       "0               0           0      0         0  \n",
       "1               0           0      0         0  \n",
       "2               1           0      0         0  \n",
       "3               1           0      0         0  \n",
       "4               1           0      0         0  \n",
       "...           ...         ...    ...       ...  \n",
       "447157          1           1      1         1  \n",
       "447158          1           1      1         1  \n",
       "447159          1           1      1         1  \n",
       "447160          1           1      1         0  \n",
       "447161          1           1      1         1  \n",
       "\n",
       "[447162 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame.drop_duplicates(train_data)\n",
    "# reset dataframe index\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing duplicates, we still have approximately 10% observations with conversion = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 2.23632098e-06],\n",
       "       [9.08814012e-01, 9.11837518e-02]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion_counts = np.unique(train_data.conversion, return_counts = True)\n",
    "conversion_counts/np.sum(conversion_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Privacy Attack Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps are as follows:\n",
    "\n",
    "- Split the data three ways:\n",
    "    - Marketer training data\n",
    "    - Adversary training data\n",
    "    - Outside data\n",
    "- Train Marketer and Adversary synthesis models\n",
    "- Compute predictions for distribution membership for outside data and compute empirical epsilon\n",
    "- Repeat the above steps many times (100 iterations in Ponte et al. 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to split into train and test sets while ensuring that the training data has an even number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_even(X, train_size, strat_var, random_state=None):\n",
    "    \n",
    "    # Split the data normally\n",
    "    # stratify based on strat var, if it exists\n",
    "    if strat_var:\n",
    "        X_train, X_test = train_test_split(\n",
    "            X, train_size=train_size, stratify=X[strat_var], random_state=random_state)\n",
    "    else:\n",
    "        X_train, X_test = train_test_split(\n",
    "            X, train_size=train_size, random_state=random_state)\n",
    "    \n",
    "    # If train set has odd number of rows\n",
    "    if len(X_train) % 2 != 0:\n",
    "        # Move the last row from train to test\n",
    "        X_test = pd.concat([X_test, X_train[-1:]], axis=0)\n",
    "        X_train = X_train[:-1]\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate utility of synthetic data based on the mean-absolute percentage error (MAPE), mean-absolute error, and mean-squared error between regression coefficients estimated on the real and synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define utility\n",
    "def utility(real_data, protected_data):\n",
    "    \n",
    "    # import error metrics\n",
    "    from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error\n",
    "\n",
    "    # estimate logistic regression coefficients for real_data\n",
    "    logit_params_original = logit_params(X = real_data.drop('conversion', axis=1), y = real_data['conversion'])\n",
    "\n",
    "    # estimate logistic regression coefficients for protected_data\n",
    "    logit_params_protected = logit_params(X = protected_data.drop('conversion', axis=1), y = protected_data['conversion'])\n",
    "\n",
    "    # compute error metrics\n",
    "    MAPE = mean_absolute_percentage_error(logit_params_original, logit_params_protected)*100\n",
    "    MAE = mean_absolute_error(logit_params_original, logit_params_protected)\n",
    "    MSE = mean_squared_error(logit_params_original, logit_params_protected)\n",
    "    return MAPE, MAE, MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for synthesis models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some default bounds for leaf values. These will be appropriately filled in during the loop below\n",
    "\n",
    "param_bounds = {\n",
    "    'tree': {\n",
    "        'f0': {  # Applies to all tree-synthesized variables\n",
    "            'min_samples_leaf': [10, 1000]  # [min, max] bounds\n",
    "        },\n",
    "        'f1': {  # Applies to all tree-synthesized variables\n",
    "            'min_samples_leaf': [5, 5]  # [min, max] bounds\n",
    "        },\n",
    "        'f2': {  # Applies to all tree-synthesized variables\n",
    "            'min_samples_leaf': [5, 5]  # [min, max] bounds\n",
    "        },\n",
    "        'f3': {  # Applies to all tree-synthesized variables\n",
    "            'min_samples_leaf': [10, 1000]  # [min, max] bounds\n",
    "        },\n",
    "        'f4': {  # Applies to all tree-synthesized variables\n",
    "            'min_samples_leaf': [5, 5]  # [min, max] bounds\n",
    "        },\n",
    "        'f5': {  # Applies to all tree-synthesized variables\n",
    "            'min_samples_leaf': [10, 1000]  # [min, max] bounds\n",
    "        },\n",
    "        'f6': {  # Applies to all tree-synthesized variables\n",
    "            'min_samples_leaf': [10, 1000]  # [min, max] bounds\n",
    "        },\n",
    "        'f7': {  # Applies to all tree-synthesized variables\n",
    "            'min_samples_leaf': [5, 5]  # [min, max] bounds\n",
    "        },\n",
    "        'f8': {  # Applies to all tree-synthesized variables\n",
    "            'min_samples_leaf': [4063, 10000]  # [min, max] bounds\n",
    "        },\n",
    "        'f9': {  # Applies to all tree-synthesized variables\n",
    "            'min_samples_leaf': [5, 5]  # [min, max] bounds\n",
    "        },\n",
    "        'f10': {  # Applies to all tree-synthesized variables\n",
    "            'min_samples_leaf': [5, 5]  # [min, max] bounds\n",
    "        },\n",
    "        'f11': {  # Applies to all tree-synthesized variables\n",
    "            'min_samples_leaf': [10, 1000]  # [min, max] bounds\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_synthetic_datasets = 10\n",
    "num_iter_optimization = 25\n",
    "num_init_optimization = 5\n",
    "random_states = [1006, 428]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Everything Up in a Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_obs = [300, 3000, 30000]\n",
    "# using 3X the desired training data size, which gets split into thirds (marketer_train, adversary_train, external_data)\n",
    "num_obs = [300, 400]\n",
    "# num_simulations = 100\n",
    "num_simulations = 5\n",
    "epsilons = {}\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are synthesizing variables out of the order in which they appear in the data, you need to re-order the initial training data to match that order. This is done in the loop below already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelized Version of attack (will run simulations in parallel to speed up processing). Still loops over values of N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_single_simulation(n, i, current_data_sample, strat_var, seed, random_states, **params):\n",
    "    # Unpack all parameters from params\n",
    "    (number_synthetic_datasets, param_bounds, num_iter_optimization, num_init_optimization) = params.values()\n",
    "    \n",
    "    # Split data into training data and external data (which won't be included in marketer or adversary training data)\n",
    "    internal_data, external_data = train_test_split_even(\n",
    "        current_data_sample, train_size=2/3, strat_var=strat_var, random_state=seed+i)\n",
    "\n",
    "    # define training sets for the marketer and the adversary\n",
    "    marketer_train, adversary_train = train_test_split(internal_data, train_size=0.5, stratify=internal_data[strat_var])\n",
    "\n",
    "    #### Define synthesis inputs for marketer ####\n",
    "\n",
    "    # define order of synthesis and the bounds of synthesis for the marketer\n",
    "    marketer_cols, marketer_steps, marketer_bounds = define_synthesis_steps(marketer_train, param_bounds)\n",
    "\n",
    "    # reorder the columns in the training data to match the synthesis order\n",
    "    marketer_train = marketer_train[marketer_cols]\n",
    "\n",
    "    # define the target variable for the user model\n",
    "    # we use the same target variable as stratification variable\n",
    "    # define the exogenous variables for the user model\n",
    "    marketer_exog_variables = list(marketer_train.drop(strat_var, axis=1).columns)\n",
    "\n",
    "    # parameter values from the training data\n",
    "    marketer_target_params = logit_params(X = marketer_train[marketer_exog_variables], y = marketer_train[strat_var])\n",
    "\n",
    "    #### Define synthesis inputs for adversary ####\n",
    "    \n",
    "    # define order of synthesis and the bounds of synthesis for the marketer\n",
    "    adversary_cols, adversary_steps, adversary_bounds = define_synthesis_steps(adversary_train, param_bounds)\n",
    "\n",
    "    # reorder the columns in the training data to match the synthesis order\n",
    "    adversary_train = adversary_train[adversary_cols]\n",
    "\n",
    "    # define the exogenous variables for the user model\n",
    "    adversary_exog_variables = list(adversary_train.drop(strat_var, axis=1).columns)\n",
    "\n",
    "    # parameter values from the training data\n",
    "    adversary_target_params = logit_params(X = adversary_train[adversary_exog_variables], y = adversary_train[strat_var])\n",
    "\n",
    "    N = len(marketer_train)/10\n",
    "    \n",
    "    def optimize_models_wrapper(data_to_synthesize, steps_to_follow, bounds_to_use, params_to_target, x_variables, random_states):\n",
    "        return [\n",
    "            optimize_models_with_param_target(train_data=data_to_synthesize,\n",
    "                                              number_synthetic_datasets=number_synthetic_datasets,\n",
    "                                              synthesis_steps=steps_to_follow,\n",
    "                                              param_bounds=bounds_to_use,\n",
    "                                              random_state=r,\n",
    "                                              target_params=params_to_target,\n",
    "                                              target_variable=strat_var,\n",
    "                                              exog_variables=x_variables,\n",
    "                                              n_iter=num_iter_optimization,\n",
    "                                              n_init=num_init_optimization) for r in random_states\n",
    "        ]\n",
    "    \n",
    "    # Parallelize model optimization\n",
    "    marketer_results = optimize_models_wrapper(marketer_train, marketer_steps, marketer_bounds, marketer_target_params, marketer_exog_variables, random_states)\n",
    "    adversary_results = optimize_models_wrapper(adversary_train, adversary_steps, adversary_bounds, adversary_target_params, adversary_exog_variables, random_states)\n",
    "    \n",
    "    # store best params\n",
    "    best_marketer_params = marketer_results[np.argmin([x['best_score'] for x in marketer_results])]['best_params']\n",
    "    best_adversary_params = adversary_results[np.argmin([x['best_score'] for x in adversary_results])]['best_params']\n",
    "    \n",
    "    # Rest of the function remains the same...\n",
    "    # train and generate with best params\n",
    "    _, marketer_sXs = perform_synthesis_with_param_target(\n",
    "        train_data=marketer_train,\n",
    "        number_synthetic_datasets=2,\n",
    "        synthesis_steps=marketer_steps,\n",
    "        target_params=marketer_target_params,\n",
    "        target_variable=strat_var,\n",
    "        exog_variables=marketer_exog_variables,\n",
    "        param_values=best_marketer_params)\n",
    "\n",
    "    _, adversary_sXs = perform_synthesis_with_param_target(\n",
    "        train_data=adversary_train,\n",
    "        number_synthetic_datasets=2,\n",
    "        synthesis_steps=adversary_steps,\n",
    "        target_params=adversary_target_params,\n",
    "        target_variable=strat_var,\n",
    "        exog_variables=adversary_exog_variables,\n",
    "        param_values=best_adversary_params)\n",
    "\n",
    "    marketer_synthetic = marketer_sXs[0]\n",
    "    adversary_synthetic = adversary_sXs[0]\n",
    "\n",
    "    # for consistent evaluation below, ensure that column orderings are the same in all data sets\n",
    "    # we haven't touched the external data yet, so we know it preserves the original column order\n",
    "    marketer_train = marketer_train[external_data.columns]\n",
    "    adversary_train = adversary_train[external_data.columns]\n",
    "    marketer_synthetic = marketer_synthetic[external_data.columns]\n",
    "    adversary_synthetic = adversary_synthetic[external_data.columns]\n",
    "\n",
    "    # evaluate utility of logistic regression coefficients\n",
    "    # the columns have been consistently reordered so coefficient orders will match\n",
    "    marketer_mape, marketer_mae, marketer_mse = utility(marketer_train, marketer_synthetic)\n",
    "    adversary_mape, adversary_mae, adversary_mse = utility(adversary_train, adversary_synthetic)\n",
    "\n",
    "    # average utility measures\n",
    "    MAPE = (marketer_mape + adversary_mape)/2\n",
    "    MAE = (marketer_mae + adversary_mae)/2\n",
    "    MSE = (marketer_mse + adversary_mse)/2\n",
    "\n",
    "    ### below code borrowed from Ponte et al. (2024)\n",
    "\n",
    "    # step 1, 2 from paper\n",
    "    bw_params = {\"bandwidth\": np.logspace(-1, 1, 20)} # vary the bandwith\n",
    "    grid_marketer = GridSearchCV(KernelDensity(), bw_params, n_jobs = 1) # cross validate for bandwiths\n",
    "    grid_marketer.fit(marketer_synthetic) # estimate pdf from train data.\n",
    "    marketer_kde = grid_marketer.best_estimator_ # get best estimator\n",
    "\n",
    "    grid_adversary = GridSearchCV(KernelDensity(), bw_params, n_jobs = 1) # cross validate (CV)\n",
    "    grid_adversary.fit(adversary_synthetic) # estimate pdf from adversary data\n",
    "    adversary_kde = grid_adversary.best_estimator_ # get best estimator from CV\n",
    "\n",
    "    density_marketer = marketer_kde.score_samples(marketer_train) # score train examples from train on pdf_train\n",
    "    density_adversary = adversary_kde.score_samples(marketer_train) # score train examples from train on pdf_adversary\n",
    "    TPR = sum(density_marketer > density_adversary)/len(density_marketer) # calculate TPR\n",
    "\n",
    "    density_marketer_new = marketer_kde.score_samples(external_data) # score eval_outside examples on train density\n",
    "    density_adversary_new = adversary_kde.score_samples(external_data) # score eval_outside examples on adversary density\n",
    "    FPR = sum(density_marketer_new > density_adversary_new)/len(density_marketer_new) # calculate FPR\n",
    "    TNR = 1 - FPR\n",
    "    FNR = 1 - TPR\n",
    "    \n",
    "    risk_vals = [(1 - (1/N) - FPR)/FNR, (1 - (1/N) - FNR)/FPR]\n",
    "    \n",
    "    return {'epsilon': math.log(risk_vals[np.argmax(risk_vals)]), 'MAPE': MAPE, 'MAE': MAE, 'MSE': MSE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "def process_n(n, strat_var):\n",
    "\n",
    "    # create current_data_sample by splitting the original data, stratified by 'conversion'\n",
    "    current_data_sample, _ = train_test_split(\n",
    "        train_data, \n",
    "        train_size=n, \n",
    "        stratify=train_data[strat_var], \n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    # Prepare parameters\n",
    "    params = {\n",
    "        'number_synthetic_datasets': number_synthetic_datasets,\n",
    "        'param_bounds': param_bounds,\n",
    "        'num_iter_optimization': num_iter_optimization,\n",
    "        'num_init_optimization': num_init_optimization\n",
    "    }\n",
    "    \n",
    "    # Process simulations in parallel\n",
    "    # using -5 to leave a few cores free to use computer while code is running\n",
    "    results = Parallel(n_jobs=-5, verbose=10)(\n",
    "        delayed(process_single_simulation)(\n",
    "            n, i, current_data_sample, strat_var, seed, random_states, **params\n",
    "        ) for i in range(num_simulations)\n",
    "    )\n",
    "    \n",
    "    return n, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run attack simulation. Save 100 empirical epsilon results for each value of n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-5)]: Using backend LokyBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-5)]: Done   2 out of   5 | elapsed:   47.0s remaining:  1.2min\n",
      "[Parallel(n_jobs=-5)]: Done   3 out of   5 | elapsed:  1.0min remaining:   40.8s\n",
      "[Parallel(n_jobs=-5)]: Done   5 out of   5 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'logit_params' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\cdbale\\AppData\\Local\\Temp\\ipykernel_80992\\597002710.py\", line 100, in process_single_simulation\n  File \"C:\\Users\\cdbale\\AppData\\Local\\Temp\\ipykernel_80992\\45553110.py\", line 8, in utility\nUnboundLocalError: cannot access local variable 'logit_params' where it is not associated with a value\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m [process_n(n, strat_var\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconversion\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m num_obs]\n",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m [process_n(n, strat_var\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconversion\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m num_obs]\n",
      "Cell \u001b[1;32mIn[11], line 22\u001b[0m, in \u001b[0;36mprocess_n\u001b[1;34m(n, strat_var)\u001b[0m\n\u001b[0;32m     13\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_synthetic_datasets\u001b[39m\u001b[38;5;124m'\u001b[39m: number_synthetic_datasets,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_bounds\u001b[39m\u001b[38;5;124m'\u001b[39m: param_bounds,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_iter_optimization\u001b[39m\u001b[38;5;124m'\u001b[39m: num_iter_optimization,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_init_optimization\u001b[39m\u001b[38;5;124m'\u001b[39m: num_init_optimization\n\u001b[0;32m     18\u001b[0m }\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Process simulations in parallel\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# using -5 to leave a few cores free to use computer while code is running\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)(\n\u001b[0;32m     23\u001b[0m     delayed(process_single_simulation)(\n\u001b[0;32m     24\u001b[0m         n, i, current_data_sample, strat_var, seed, random_states, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m     25\u001b[0m     ) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_simulations)\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n, results\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'logit_params' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "results = [process_n(n, strat_var='conversion') for n in num_obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to the original format\n",
    "epsilons = {n: results[i][1] for i, n in enumerate(num_obs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_results = pd.DataFrame.from_dict(epsilons)\n",
    "epsilon_results.to_csv('empirical_epsilon_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900      0.252496\n",
       "9000     0.129666\n",
       "90000    0.061733\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon_results.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
