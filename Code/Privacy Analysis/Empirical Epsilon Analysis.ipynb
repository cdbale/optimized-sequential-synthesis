{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Assessing Privacy Risk Using the Attack from Ponte et al. (2024)\n",
    "\n",
    "https://github.com/GilianPonte/whereswaldoIJRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "%matplotlib inline\n",
    "\n",
    "# Add the parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Then import\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a subset of the Criteo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../../Data/Criteo/cleaned_criteo_small.gz\",\n",
    "                         compression='gzip', \n",
    "                         sep='\\,',\n",
    "                         header=0,\n",
    "                         engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicates and reset index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>treatment</th>\n",
       "      <th>conversion</th>\n",
       "      <th>visit</th>\n",
       "      <th>exposure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.954807</td>\n",
       "      <td>2.368327</td>\n",
       "      <td>2.178833</td>\n",
       "      <td>1.480282</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>20.349663</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>2.100938</td>\n",
       "      <td>48.158740</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.100481</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.105887</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.275765</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>53.083067</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.945821</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.139045</td>\n",
       "      <td>9.914112</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>46.910867</td>\n",
       "      <td>3.486706</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.177230</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.105887</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.089715</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>53.083067</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.274234</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.105887</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>53.083067</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99904</th>\n",
       "      <td>3.037003</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.184994</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.275765</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>47.003884</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99905</th>\n",
       "      <td>3.286020</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.105887</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.275765</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>53.083067</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99906</th>\n",
       "      <td>3.285632</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.105887</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.275765</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>53.083067</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99907</th>\n",
       "      <td>2.534995</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.108605</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>1.342378</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>43.484412</td>\n",
       "      <td>3.572938</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99908</th>\n",
       "      <td>2.534995</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.130229</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>1.342378</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>45.746539</td>\n",
       "      <td>3.438644</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99909 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             f0        f1        f2          f3        f4         f5  \\\n",
       "0      2.954807  2.368327  2.178833    1.480282  2.330251  20.349663   \n",
       "1      3.100481  2.308533  2.105887  107.757316  2.330251  61.279994   \n",
       "2      2.945821  2.308533  2.139045    9.914112  2.330251  61.279994   \n",
       "3      3.177230  2.308533  2.105887  107.757316  2.330251  61.279994   \n",
       "4      3.274234  2.308533  2.105887  107.757316  2.330251  61.279994   \n",
       "...         ...       ...       ...         ...       ...        ...   \n",
       "99904  3.037003  2.308533  2.184994  107.757316  2.330251  61.279994   \n",
       "99905  3.286020  2.308533  2.105887  107.757316  2.330251  61.279994   \n",
       "99906  3.285632  2.308533  2.105887  107.757316  2.330251  61.279994   \n",
       "99907  2.534995  2.308533  2.108605  107.757316  2.330251  61.279994   \n",
       "99908  2.534995  2.308533  2.130229  107.757316  2.330251  61.279994   \n",
       "\n",
       "             f6        f7         f8        f9       f10      f11  treatment  \\\n",
       "0      0.000205  2.100938  48.158740  2.579463  1.667778  0.84478          1   \n",
       "1      0.275765  1.575636  53.083067  2.579463  1.667778  0.84478          1   \n",
       "2      0.003786  1.575636  46.910867  3.486706  1.667778  0.84478          0   \n",
       "3      0.089715  1.575636  53.083067  2.579463  1.667778  0.84478          0   \n",
       "4      0.000003  1.575636  53.083067  2.579463  1.667778  0.84478          1   \n",
       "...         ...       ...        ...       ...       ...      ...        ...   \n",
       "99904  0.275765  1.575636  47.003884  2.579463  1.667778  0.84478          1   \n",
       "99905  0.275765  1.575636  53.083067  2.579463  1.667778  0.84478          1   \n",
       "99906  0.275765  1.575636  53.083067  2.579463  1.667778  0.84478          1   \n",
       "99907  1.342378  1.575636  43.484412  3.572938  1.667778  0.84478          1   \n",
       "99908  1.342378  1.575636  45.746539  3.438644  1.667778  0.84478          0   \n",
       "\n",
       "       conversion  visit  exposure  \n",
       "0               0      0         0  \n",
       "1               0      0         0  \n",
       "2               0      0         0  \n",
       "3               0      0         0  \n",
       "4               0      0         0  \n",
       "...           ...    ...       ...  \n",
       "99904           0      0         0  \n",
       "99905           0      0         0  \n",
       "99906           0      0         0  \n",
       "99907           0      0         0  \n",
       "99908           0      0         0  \n",
       "\n",
       "[99909 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame.drop_duplicates(train_data)\n",
    "# reset dataframe index\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Privacy Attack Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps are as follows:\n",
    "\n",
    "- Split the data three ways:\n",
    "    - Marketer training data\n",
    "    - Adversary training data\n",
    "    - Outside data\n",
    "- Train Marketer and Adversary synthesis models\n",
    "- Compute predictions for distribution membership for outside data and compute empirical epsilon\n",
    "- Repeat the above steps many times (100 iterations in Ponte et al. 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to split into train and test sets while ensuring that the training data has an even number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_even(X, train_size, random_state=None):\n",
    "    # Split the data normally\n",
    "    X_train, X_test = train_test_split(\n",
    "        X, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # If train set has odd number of rows\n",
    "    if len(X_train) % 2 != 0:\n",
    "        # Move the last row from train to test\n",
    "        X_test = pd.concat([X_test, X_train[-1:]], axis=0)\n",
    "        X_train = X_train[:-1]\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for synthesis models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthesis steps\n",
    "# written as a list of tuples (features, model)\n",
    "synthesis_steps = [\n",
    "    ([\"f0\", \"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"f8\", \"f9\", \"f10\", \"f11\"], 'gmm'),\n",
    "    ('treatment', 'multinomial'),\n",
    "    ('exposure', 'multinomial'),\n",
    "    ('visit', 'multinomial'),\n",
    "    ('conversion', 'multinomial')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter bounds\n",
    "param_bounds = {\n",
    "    'gmm': {\n",
    "        'num_components': (10, 50.99),\n",
    "    },\n",
    "    'multinomial': {\n",
    "        'treatment': {'C': (0.001, 3)},\n",
    "        'exposure': {'C': (0.001, 3)},\n",
    "        'visit': {'C': (0.001, 3)},\n",
    "        'conversion': {'C': (0.001, 3)}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_synthetic_datasets = 10\n",
    "num_iter_optimization = 25\n",
    "num_init_optimization = 5\n",
    "random_states = [1006, 428]\n",
    "poly_degree_mnl = 2\n",
    "poly_degree_pmse = 2\n",
    "interaction_only = True\n",
    "gmm_n_init = 3\n",
    "covariance_type = \"diag\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Everything Up in a Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs = [300, 3000, 30000]\n",
    "num_simulations = 100\n",
    "epsilons = {}\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are synthesizing variables out of the order in which they appear in the data, you need to re-order the initial training data to match that order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order training data variables based on synthesis order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = []\n",
    "for item in synthesis_steps:\n",
    "    name = item[0]\n",
    "    if type(name) == list:\n",
    "        for i in name:\n",
    "            var_names.append(i)\n",
    "    else:\n",
    "        var_names.append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>treatment</th>\n",
       "      <th>exposure</th>\n",
       "      <th>visit</th>\n",
       "      <th>conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.954807</td>\n",
       "      <td>2.368327</td>\n",
       "      <td>2.178833</td>\n",
       "      <td>1.480282</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>20.349663</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>2.100938</td>\n",
       "      <td>48.158740</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.100481</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.105887</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.275765</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>53.083067</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.945821</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.139045</td>\n",
       "      <td>9.914112</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>46.910867</td>\n",
       "      <td>3.486706</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.177230</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.105887</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.089715</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>53.083067</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.274234</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.105887</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>53.083067</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99904</th>\n",
       "      <td>3.037003</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.184994</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.275765</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>47.003884</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99905</th>\n",
       "      <td>3.286020</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.105887</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.275765</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>53.083067</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99906</th>\n",
       "      <td>3.285632</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.105887</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>0.275765</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>53.083067</td>\n",
       "      <td>2.579463</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99907</th>\n",
       "      <td>2.534995</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.108605</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>1.342378</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>43.484412</td>\n",
       "      <td>3.572938</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99908</th>\n",
       "      <td>2.534995</td>\n",
       "      <td>2.308533</td>\n",
       "      <td>2.130229</td>\n",
       "      <td>107.757316</td>\n",
       "      <td>2.330251</td>\n",
       "      <td>61.279994</td>\n",
       "      <td>1.342378</td>\n",
       "      <td>1.575636</td>\n",
       "      <td>45.746539</td>\n",
       "      <td>3.438644</td>\n",
       "      <td>1.667778</td>\n",
       "      <td>0.84478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99909 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             f0        f1        f2          f3        f4         f5  \\\n",
       "0      2.954807  2.368327  2.178833    1.480282  2.330251  20.349663   \n",
       "1      3.100481  2.308533  2.105887  107.757316  2.330251  61.279994   \n",
       "2      2.945821  2.308533  2.139045    9.914112  2.330251  61.279994   \n",
       "3      3.177230  2.308533  2.105887  107.757316  2.330251  61.279994   \n",
       "4      3.274234  2.308533  2.105887  107.757316  2.330251  61.279994   \n",
       "...         ...       ...       ...         ...       ...        ...   \n",
       "99904  3.037003  2.308533  2.184994  107.757316  2.330251  61.279994   \n",
       "99905  3.286020  2.308533  2.105887  107.757316  2.330251  61.279994   \n",
       "99906  3.285632  2.308533  2.105887  107.757316  2.330251  61.279994   \n",
       "99907  2.534995  2.308533  2.108605  107.757316  2.330251  61.279994   \n",
       "99908  2.534995  2.308533  2.130229  107.757316  2.330251  61.279994   \n",
       "\n",
       "             f6        f7         f8        f9       f10      f11  treatment  \\\n",
       "0      0.000205  2.100938  48.158740  2.579463  1.667778  0.84478          1   \n",
       "1      0.275765  1.575636  53.083067  2.579463  1.667778  0.84478          1   \n",
       "2      0.003786  1.575636  46.910867  3.486706  1.667778  0.84478          0   \n",
       "3      0.089715  1.575636  53.083067  2.579463  1.667778  0.84478          0   \n",
       "4      0.000003  1.575636  53.083067  2.579463  1.667778  0.84478          1   \n",
       "...         ...       ...        ...       ...       ...      ...        ...   \n",
       "99904  0.275765  1.575636  47.003884  2.579463  1.667778  0.84478          1   \n",
       "99905  0.275765  1.575636  53.083067  2.579463  1.667778  0.84478          1   \n",
       "99906  0.275765  1.575636  53.083067  2.579463  1.667778  0.84478          1   \n",
       "99907  1.342378  1.575636  43.484412  3.572938  1.667778  0.84478          1   \n",
       "99908  1.342378  1.575636  45.746539  3.438644  1.667778  0.84478          0   \n",
       "\n",
       "       exposure  visit  conversion  \n",
       "0             0      0           0  \n",
       "1             0      0           0  \n",
       "2             0      0           0  \n",
       "3             0      0           0  \n",
       "4             0      0           0  \n",
       "...         ...    ...         ...  \n",
       "99904         0      0           0  \n",
       "99905         0      0           0  \n",
       "99906         0      0           0  \n",
       "99907         0      0           0  \n",
       "99908         0      0           0  \n",
       "\n",
       "[99909 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data[var_names]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelized Version of attack (will run simulations in parallel to speed up processing). Still loops over values of N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_single_simulation(n, i, current_data_sample, seed, random_states, **params):\n",
    "    # Unpack all parameters from params\n",
    "    (number_synthetic_datasets, synthesis_steps, param_bounds, poly_degree_mnl, \n",
    "     poly_degree_pmse, interaction_only, covariance_type, gmm_n_init, \n",
    "     num_iter_optimization, num_init_optimization) = params.values()\n",
    "    \n",
    "    # Split data\n",
    "    internal_data, external_data = train_test_split_even(\n",
    "        current_data_sample, train_size=0.67, random_state=seed+i\n",
    "    )\n",
    "    marketer_train, adversary_train = train_test_split(internal_data, train_size=0.5)\n",
    "\n",
    "    N = len(marketer_train)/10\n",
    "    \n",
    "    def optimize_models_wrapper(data_to_synthesize, random_states):\n",
    "        return [\n",
    "            optimize_models(\n",
    "                train_data=data_to_synthesize,\n",
    "                number_synthetic_datasets=number_synthetic_datasets,\n",
    "                synthesis_steps=synthesis_steps,\n",
    "                param_bounds=param_bounds,\n",
    "                poly_degree_mnl=poly_degree_mnl,\n",
    "                poly_degree_pmse=poly_degree_pmse,\n",
    "                interaction_only=interaction_only,\n",
    "                covariance_type=covariance_type,\n",
    "                gmm_n_init=gmm_n_init,\n",
    "                random_state=r,\n",
    "                num_iter_optimization=num_iter_optimization,\n",
    "                num_init_optimization=num_init_optimization\n",
    "            ) for r in random_states\n",
    "        ]\n",
    "    \n",
    "    # Parallelize model optimization\n",
    "    marketer_results = optimize_models_wrapper(marketer_train, random_states)\n",
    "    adversary_results = optimize_models_wrapper(adversary_train, random_states)\n",
    "    \n",
    "    # store best params\n",
    "    best_marketer_params = marketer_results[np.argmin([x['best_score'] for x in marketer_results])]['best_params']\n",
    "    best_adversary_params = adversary_results[np.argmin([x['best_score'] for x in adversary_results])]['best_params']\n",
    "    \n",
    "    # Rest of the function remains the same...\n",
    "    # train and generate with best params\n",
    "    _, marketer_sXs = perform_synthesis(train_data=marketer_train,\n",
    "                                        number_synthetic_datasets=2,\n",
    "                                        poly_degree_mnl=poly_degree_mnl,\n",
    "                                        poly_degree_pmse=poly_degree_pmse,\n",
    "                                        interaction_only=interaction_only,\n",
    "                                        covariance_type=covariance_type,\n",
    "                                        gmm_n_init=gmm_n_init,\n",
    "                                        synthesis_steps=synthesis_steps,\n",
    "                                        param_values=best_marketer_params)\n",
    "\n",
    "    _, adversary_sXs = perform_synthesis(train_data=adversary_train,\n",
    "                                        number_synthetic_datasets=2,\n",
    "                                        poly_degree_mnl=poly_degree_mnl,\n",
    "                                        poly_degree_pmse=poly_degree_pmse,\n",
    "                                        interaction_only=interaction_only,\n",
    "                                        covariance_type=covariance_type,\n",
    "                                        gmm_n_init=gmm_n_init,\n",
    "                                        synthesis_steps=synthesis_steps,\n",
    "                                        param_values=best_adversary_params)\n",
    "\n",
    "    marketer_synthetic = marketer_sXs[0]\n",
    "    adversary_synthetic = adversary_sXs[0]\n",
    "\n",
    "    ### below code borrowed from Ponte et al. (2024)\n",
    "\n",
    "    # step 1, 2 from paper\n",
    "    bw_params = {\"bandwidth\": np.logspace(-1, 1, 20)} # vary the bandwith\n",
    "    grid_marketer = GridSearchCV(KernelDensity(), bw_params, n_jobs = 1) # cross validate for bandwiths\n",
    "    grid_marketer.fit(marketer_synthetic) # estimate pdf from train data.\n",
    "    marketer_kde = grid_marketer.best_estimator_ # get best estimator\n",
    "\n",
    "    grid_adversary = GridSearchCV(KernelDensity(), bw_params, n_jobs = 1) # cross validate (CV)\n",
    "    grid_adversary.fit(adversary_synthetic) # estimate pdf from adversary data\n",
    "    adversary_kde = grid_adversary.best_estimator_ # get best estimator from CV\n",
    "\n",
    "    density_marketer = marketer_kde.score_samples(marketer_train) # score train examples from train on pdf_train\n",
    "    density_adversary = adversary_kde.score_samples(marketer_train) # score train examples from train on pdf_adversary\n",
    "    TPR = sum(density_marketer > density_adversary)/len(density_marketer) # calculate TPR\n",
    "\n",
    "    density_marketer_new = marketer_kde.score_samples(external_data) # score eval_outside examples on train density\n",
    "    density_adversary_new = adversary_kde.score_samples(external_data) # score eval_outside examples on adversary density\n",
    "    FPR = sum(density_marketer_new > density_adversary_new)/len(density_marketer_new) # calculate FPR\n",
    "    TNR = 1 - FPR\n",
    "    FNR = 1 - TPR\n",
    "    \n",
    "    risk_vals = [(1 - (1/N) - FPR)/FNR, (1 - (1/N) - FNR)/FPR]\n",
    "    \n",
    "    return math.log(risk_vals[np.argmax(risk_vals)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "def process_n(n):\n",
    "    current_data_sample, _ = train_test_split(\n",
    "        train_data, \n",
    "        train_size=n, \n",
    "        stratify=train_data['conversion'], \n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    # Prepare parameters\n",
    "    params = {\n",
    "        'number_synthetic_datasets': number_synthetic_datasets,\n",
    "        'synthesis_steps': synthesis_steps,\n",
    "        'param_bounds': param_bounds,\n",
    "        'poly_degree_mnl': poly_degree_mnl,\n",
    "        'poly_degree_pmse': poly_degree_pmse,\n",
    "        'interaction_only': interaction_only,\n",
    "        'covariance_type': covariance_type,\n",
    "        'gmm_n_init': gmm_n_init,\n",
    "        'num_iter_optimization': num_iter_optimization,\n",
    "        'num_init_optimization': num_init_optimization\n",
    "    }\n",
    "    \n",
    "    # Process simulations in parallel\n",
    "    results = Parallel(n_jobs=-5, verbose=10)(\n",
    "        delayed(process_single_simulation)(\n",
    "            n, i, current_data_sample, seed, random_states, **params\n",
    "        ) for i in range(num_simulations)\n",
    "    )\n",
    "    \n",
    "    return n, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run attack simulation. Save 100 empirical epsilon results for each value of n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-5)]: Using backend LokyBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-5)]: Done   5 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-5)]: Done  16 tasks      | elapsed:  6.3min\n"
     ]
    }
   ],
   "source": [
    "results = [process_n(n) for n in num_obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to the original format\n",
    "epsilons = {n: results[i][1] for i, n in enumerate(num_obs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_results = pd.DataFrame.from_dict(epsilons)\n",
    "epsilon_results.to_csv('empirical_epsilon_results.csv', row.names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter('ignore')\n",
    "\n",
    "#     for n in num_obs:\n",
    "\n",
    "#         current_data_sample, _ = train_test_split(train_data, train_size = n, stratify = train_data['conversion'], random_state=seed)\n",
    "\n",
    "#         epsilons[n] = []\n",
    "\n",
    "#         for i in range(num_simulations):\n",
    "\n",
    "#             # split data\n",
    "#             internal_data, external_data = train_test_split_even(current_data_sample, train_size=0.67, random_state=seed+i)\n",
    "#             marketer_train, adversary_train = train_test_split(internal_data, train_size=0.5)\n",
    "\n",
    "#             # marketer synthesis\n",
    "#             marketer_optimization_results = [optimize_models(train_data=marketer_train, \n",
    "#                                                              number_synthetic_datasets=number_synthetic_datasets,\n",
    "#                                                              synthesis_steps=synthesis_steps,\n",
    "#                                                              param_bounds=param_bounds,\n",
    "#                                                              poly_degree_mnl=poly_degree_mnl,\n",
    "#                                                              poly_degree_pmse=poly_degree_pmse,\n",
    "#                                                              interaction_only=interaction_only,\n",
    "#                                                              covariance_type=covariance_type,\n",
    "#                                                              gmm_n_init=gmm_n_init,\n",
    "#                                                              random_state=r,\n",
    "#                                                              num_iter_optimization=num_iter_optimization,\n",
    "#                                                              num_init_optimization=num_init_optimization) for r in random_states]\n",
    "\n",
    "#             # adversary synthesis\n",
    "#             adversary_optimization_results = [optimize_models(train_data=adversary_train, \n",
    "#                                                               number_synthetic_datasets=number_synthetic_datasets,\n",
    "#                                                               synthesis_steps=synthesis_steps,\n",
    "#                                                               param_bounds=param_bounds,\n",
    "#                                                               poly_degree_mnl=poly_degree_mnl,\n",
    "#                                                               poly_degree_pmse=poly_degree_pmse,\n",
    "#                                                               interaction_only=interaction_only,\n",
    "#                                                               covariance_type=covariance_type,\n",
    "#                                                               gmm_n_init=gmm_n_init,\n",
    "#                                                               random_state=r,\n",
    "#                                                               num_iter_optimization=num_iter_optimization,\n",
    "#                                                               num_init_optimization=num_init_optimization) for r in random_states]\n",
    "\n",
    "#             # store best params\n",
    "#             best_marketer_params = marketer_optimization_results[np.argmin([x['best_score'] for x in marketer_optimization_results])]['best_params']\n",
    "#             best_adversary_params = adversary_optimization_results[np.argmin([x['best_score'] for x in adversary_optimization_results])]['best_params']\n",
    "\n",
    "#             # train and generate with best params\n",
    "#             marketer_ratios, marketer_sXs = perform_synthesis(train_data=marketer_train,\n",
    "#                                                               number_synthetic_datasets=2,\n",
    "#                                                               poly_degree_mnl=poly_degree_mnl,\n",
    "#                                                               poly_degree_pmse=poly_degree_pmse,\n",
    "#                                                               interaction_only=interaction_only,\n",
    "#                                                               covariance_type=covariance_type,\n",
    "#                                                               gmm_n_init=gmm_n_init,\n",
    "#                                                               synthesis_steps=synthesis_steps,\n",
    "#                                                               param_values=best_marketer_params)\n",
    "\n",
    "#             adversary_ratios, adversary_sXs = perform_synthesis(train_data=adversary_train,\n",
    "#                                                                 number_synthetic_datasets=2,\n",
    "#                                                                 poly_degree_mnl=poly_degree_mnl,\n",
    "#                                                                 poly_degree_pmse=poly_degree_pmse,\n",
    "#                                                                 interaction_only=interaction_only,\n",
    "#                                                                 covariance_type=covariance_type,\n",
    "#                                                                 gmm_n_init=gmm_n_init,\n",
    "#                                                                 synthesis_steps=synthesis_steps,\n",
    "#                                                                 param_values=best_adversary_params)\n",
    "\n",
    "#             marketer_synthetic = marketer_sXs[0]\n",
    "#             adversary_synthetic = adversary_sXs[0]\n",
    "\n",
    "#             ### below code borrowed from Ponte et al. (2024)\n",
    "#             # to prevent a naive model\n",
    "#             N = len(marketer_train)/10\n",
    "\n",
    "#             # step 1, 2 from paper\n",
    "#             params = {\"bandwidth\": np.logspace(-1, 1, 20)} # vary the bandwith\n",
    "#             grid_marketer = GridSearchCV(KernelDensity(), params, n_jobs = -1) # cross validate for bandwiths\n",
    "#             grid_marketer.fit(marketer_synthetic) # estimate pdf from train data.\n",
    "#             marketer_kde = grid_marketer.best_estimator_ # get best estimator\n",
    "\n",
    "#             grid_adversary = GridSearchCV(KernelDensity(), params, n_jobs = -1) # cross validate (CV)\n",
    "#             grid_adversary.fit(adversary_synthetic) # estimate pdf from adversary data\n",
    "#             adversary_kde = grid_adversary.best_estimator_ # get best estimator from CV\n",
    "\n",
    "#             density_marketer = marketer_kde.score_samples(marketer_train) # score train examples from train on pdf_train\n",
    "#             density_adversary = adversary_kde.score_samples(marketer_train) # score train examples from train on pdf_adversary\n",
    "#             TPR = sum(density_marketer > density_adversary)/len(density_marketer) # calculate TPR\n",
    "\n",
    "#             density_marketer_new = marketer_kde.score_samples(external_data) # score eval_outside examples on train density\n",
    "#             density_adversary_new = adversary_kde.score_samples(external_data) # score eval_outside examples on adversary density\n",
    "#             FPR = sum(density_marketer_new > density_adversary_new)/len(density_marketer_new) # calculate FPR\n",
    "#             TNR = 1 - FPR\n",
    "#             FNR = 1 - TPR\n",
    "  \n",
    "#             risk_vals = [(1 - (1/N) - FPR)/FNR, (1 - (1/N) - FNR)/FPR]\n",
    "#             epsilons[n].append(math.log(risk_vals[np.argmax(risk_vals)])) # append resulting epsilon to epsilons\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
