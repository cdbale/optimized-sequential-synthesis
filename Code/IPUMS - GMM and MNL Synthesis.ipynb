{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f48262",
   "metadata": {},
   "source": [
    "This notebook performs the synthesis using our proposed synthesization approach applied to the IPUMS data. The synthesis model is a CART. Logistic regression with three way interactions is used as the pMSE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3f5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction\n",
    "\n",
    "from helper_functions import *\n",
    "\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8ccbc",
   "metadata": {},
   "source": [
    "Import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730c2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standardized lat/long location data\n",
    "train_data = pd.read_csv(\"../Data/IPUMS/cleaned_ipums_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6584fe74",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2dcd1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incwage</th>\n",
       "      <th>years_of_educ</th>\n",
       "      <th>potential_experience</th>\n",
       "      <th>non_white</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579435</td>\n",
       "      <td>1.109071</td>\n",
       "      <td>-0.039398</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.564281</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.369388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.748874</td>\n",
       "      <td>-0.044869</td>\n",
       "      <td>-1.347515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.935257</td>\n",
       "      <td>-0.814163</td>\n",
       "      <td>-1.511030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.164308</td>\n",
       "      <td>-0.429516</td>\n",
       "      <td>1.186962</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197751</th>\n",
       "      <td>-0.092296</td>\n",
       "      <td>1.109071</td>\n",
       "      <td>-0.448185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197752</th>\n",
       "      <td>-0.854774</td>\n",
       "      <td>1.109071</td>\n",
       "      <td>-0.611699</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197753</th>\n",
       "      <td>0.521921</td>\n",
       "      <td>1.777461</td>\n",
       "      <td>0.063806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197754</th>\n",
       "      <td>-0.981853</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>-0.448185</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197755</th>\n",
       "      <td>0.865036</td>\n",
       "      <td>1.109071</td>\n",
       "      <td>1.105204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197756 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         incwage  years_of_educ  potential_experience  non_white  sex\n",
       "0      -0.579435       1.109071             -0.039398          0    1\n",
       "1       0.564281       0.724424              0.369388          0    0\n",
       "2      -0.748874      -0.044869             -1.347515          0    0\n",
       "3      -0.935257      -0.814163             -1.511030          0    0\n",
       "4      -0.164308      -0.429516              1.186962          1    0\n",
       "...          ...            ...                   ...        ...  ...\n",
       "197751 -0.092296       1.109071             -0.448185          0    0\n",
       "197752 -0.854774       1.109071             -0.611699          0    1\n",
       "197753  0.521921       1.777461              0.063806          0    0\n",
       "197754 -0.981853       0.724424             -0.448185          0    1\n",
       "197755  0.865036       1.109071              1.105204          0    0\n",
       "\n",
       "[197756 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14972140",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ef6c3",
   "metadata": {},
   "source": [
    "Functions for logistic and multinomial logistic regression synthesizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6927923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models_mn(#overall parameters\n",
    "                    train_data,\n",
    "                    number_synthetic_datasets,\n",
    "                    # hyperparameters for GMM, end with underscore means Bayesian optimization will choose\n",
    "                    number_gmm_initializations,\n",
    "                    num_components_,\n",
    "                    # hyperparameters for CART, end with underscore means Bayesian optimization will choose\n",
    "                    C_non_white_,\n",
    "                    C_sex_):\n",
    "    \n",
    "    num_samples = train_data.shape[0]\n",
    "    \n",
    "    ########## Code for GMM ############\n",
    "    \n",
    "    # fit GMM model\n",
    "    GMM = GaussianMixture(num_components_, n_init=number_gmm_initializations, init_params=\"k-means++\", random_state=rng).fit(train_data.loc[:,[\"incwage\", \"years_of_educ\", \"potential_experience\"]])\n",
    "    \n",
    "    # list for synthetic datasets\n",
    "    sXs = []\n",
    "    \n",
    "    # generate and store number_synthetic_datasets synthetic datasets\n",
    "    for i in range(number_synthetic_datasets):\n",
    "        sX = GMM.sample(num_samples)[0]\n",
    "        sX = pd.DataFrame(sX)\n",
    "        sX.columns = [\"incwage\", \"years_of_educ\", \"potential_experience\"]\n",
    "        sXs.append(sX)\n",
    "        \n",
    "    ####################################################################################################\n",
    "        \n",
    "    ########### Code for non-white MN ##########\n",
    "    \n",
    "    synth_non_white_vars = multinomial_synthesizer(orig_data=train_data.loc[:,[\"incwage\", \"years_of_educ\", \"potential_experience\"]], \n",
    "                                                   synth_data_sets=sXs, \n",
    "                                                   target=train_data.non_white, \n",
    "                                                   penalty_param=C_non_white_)\n",
    "    \n",
    "    sXs = [pd.concat([Y, synth_non_white_vars[i]], axis=1) for i,Y in enumerate(sXs)]\n",
    "        \n",
    "    ####################################################################################################\n",
    "        \n",
    "    ########### Code for sex MN ##########\n",
    "    \n",
    "    synth_sex_vars = multinomial_synthesizer(orig_data=train_data.loc[:,[\"incwage\", \"years_of_educ\", \"potential_experience\", \"non_white\"]], \n",
    "                                             synth_data_sets=sXs, \n",
    "                                             target=train_data.sex, \n",
    "                                             penalty_param=C_sex_)\n",
    "    \n",
    "    sXs = [pd.concat([Y, synth_sex_vars[i]], axis=1) for i,Y in enumerate(sXs)]\n",
    "        \n",
    "    ####################################################################################################\n",
    "        \n",
    "    ###### Calculate pMSE ratios ######\n",
    "    pmse_ratios = [pmse_ratio(train_data, Y) for Y in sXs]\n",
    "    \n",
    "    return pmse_ratios, sXs, GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b65e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_models_mn(train_data,\n",
    "                       number_synthetic_datasets,\n",
    "                       number_gmm_initializations,\n",
    "                       random_state):\n",
    "\n",
    "    def evaluate_models(num_components_, C_non_white_, C_sex_):\n",
    "\n",
    "        pmse_ratios, _, _ = train_models_mn(train_data=train_data,\n",
    "                                            number_synthetic_datasets=number_synthetic_datasets,\n",
    "                                            number_gmm_initializations=number_gmm_initializations,\n",
    "                                            num_components_=int(num_components_),\n",
    "                                            C_non_white_=C_non_white_,\n",
    "                                            C_sex_=C_sex_)\n",
    "        \n",
    "        return -1 * ((1 - np.mean(pmse_ratios))**2)\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=evaluate_models,\n",
    "        pbounds={\n",
    "            \"num_components_\": (10, 200.99),\n",
    "            \"C_non_white_\": (0.001, 3),\n",
    "            \"C_sex_\": (0.001, 3)\n",
    "        },\n",
    "        random_state=random_state)\n",
    "    \n",
    "    utility = UtilityFunction(kind=\"ei\", xi=1e-02)\n",
    "    optimizer.maximize(init_points=5, n_iter=25, acquisition_function=utility)\n",
    "    print(\"Final Result: \", optimizer.max)\n",
    "    return optimizer.max, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4d62c3",
   "metadata": {},
   "source": [
    "The default value for $\\alpha = 1e-06$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b295a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd = 10\n",
    "ngi = 2\n",
    "random_states = [np.random.RandomState(1006), np.random.RandomState(428)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93c78ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | C_non_... |  C_sex_   | num_co... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[30m1         | \u001b[30m-0.07647  | \u001b[30m2.23      | \u001b[30m0.68      | \u001b[30m132.7     |\n",
      "| \u001b[30m2         | \u001b[30m-0.1778   | \u001b[30m2.647     | \u001b[30m2.222     | \u001b[30m147.8     |\n",
      "| \u001b[30m3         | \u001b[30m-592.1    | \u001b[30m0.8867    | \u001b[30m1.577     | \u001b[30m43.19     |\n",
      "| \u001b[30m4         | \u001b[30m-0.9134   | \u001b[30m2.436     | \u001b[30m2.548     | \u001b[30m58.99     |\n",
      "| \u001b[30m5         | \u001b[30m-71.34    | \u001b[30m0.7125    | \u001b[30m1.376     | \u001b[30m53.72     |\n",
      "| \u001b[35m6         | \u001b[35m-0.04853  | \u001b[35m2.438     | \u001b[35m1.451     | \u001b[35m140.2     |\n",
      "| \u001b[30m7         | \u001b[30m-201.2    | \u001b[30m0.001     | \u001b[30m0.001     | \u001b[30m68.63     |\n",
      "| \u001b[30m8         | \u001b[30m-192.1    | \u001b[30m0.001     | \u001b[30m0.001     | \u001b[30m156.6     |\n",
      "| \u001b[30m9         | \u001b[30m-12.98    | \u001b[30m0.001     | \u001b[30m3.0       | \u001b[30m125.4     |\n",
      "| \u001b[30m10        | \u001b[30m-81.25    | \u001b[30m3.0       | \u001b[30m0.001     | \u001b[30m116.8     |\n",
      "| \u001b[30m11        | \u001b[30m-13.16    | \u001b[30m0.001     | \u001b[30m3.0       | \u001b[30m144.1     |\n",
      "| \u001b[30m12        | \u001b[30m-0.07067  | \u001b[30m3.0       | \u001b[30m3.0       | \u001b[30m201.0     |\n",
      "| \u001b[30m13        | \u001b[30m-206.2    | \u001b[30m0.001     | \u001b[30m0.001     | \u001b[30m193.3     |\n",
      "| \u001b[30m14        | \u001b[30m-97.93    | \u001b[30m3.0       | \u001b[30m0.001     | \u001b[30m144.6     |\n",
      "| \u001b[30m15        | \u001b[30m-14.49    | \u001b[30m0.001     | \u001b[30m3.0       | \u001b[30m136.8     |\n",
      "| \u001b[35m16        | \u001b[35m-0.02566  | \u001b[35m3.0       | \u001b[35m3.0       | \u001b[35m137.6     |\n",
      "| \u001b[30m17        | \u001b[30m-124.8    | \u001b[30m3.0       | \u001b[30m0.001     | \u001b[30m127.3     |\n",
      "| \u001b[30m18        | \u001b[30m-96.54    | \u001b[30m2.338     | \u001b[30m0.001     | \u001b[30m136.3     |\n",
      "| \u001b[30m19        | \u001b[30m-18.65    | \u001b[30m0.001     | \u001b[30m3.0       | \u001b[30m131.4     |\n",
      "| \u001b[35m20        | \u001b[35m-0.000283 | \u001b[35m2.253     | \u001b[35m3.0       | \u001b[35m140.6     |\n",
      "| \u001b[30m21        | \u001b[30m-0.02773  | \u001b[30m3.0       | \u001b[30m3.0       | \u001b[30m132.8     |\n",
      "| \u001b[30m22        | \u001b[30m-13.48    | \u001b[30m0.001     | \u001b[30m3.0       | \u001b[30m148.6     |\n",
      "| \u001b[30m23        | \u001b[30m-1.329e+0 | \u001b[30m3.0       | \u001b[30m0.001     | \u001b[30m10.0      |\n",
      "| \u001b[30m24        | \u001b[30m-14.9     | \u001b[30m0.001     | \u001b[30m3.0       | \u001b[30m95.33     |\n",
      "| \u001b[30m25        | \u001b[30m-0.06464  | \u001b[30m3.0       | \u001b[30m3.0       | \u001b[30m175.6     |\n",
      "| \u001b[30m26        | \u001b[30m-16.27    | \u001b[30m0.001     | \u001b[30m3.0       | \u001b[30m107.9     |\n",
      "| \u001b[30m27        | \u001b[30m-0.7245   | \u001b[30m3.0       | \u001b[30m3.0       | \u001b[30m81.77     |\n",
      "| \u001b[30m28        | \u001b[30m-73.96    | \u001b[30m3.0       | \u001b[30m0.001     | \u001b[30m90.83     |\n",
      "| \u001b[30m29        | \u001b[30m-0.05109  | \u001b[30m3.0       | \u001b[30m3.0       | \u001b[30m165.2     |\n",
      "| \u001b[30m30        | \u001b[30m-0.4764   | \u001b[30m3.0       | \u001b[30m3.0       | \u001b[30m188.1     |\n",
      "=============================================================\n",
      "Final Result:  {'target': -0.0002834083111841256, 'params': {'C_non_white_': 2.2533432389600176, 'C_sex_': 3.0, 'num_components_': 140.62447738426155}}\n",
      "|   iter    |  target   | C_non_... |  C_sex_   | num_co... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[30m1         | \u001b[30m-0.1009   | \u001b[30m2.455     | \u001b[30m2.623     | \u001b[30m89.92     |\n",
      "| \u001b[30m2         | \u001b[30m-1.142e+0 | \u001b[30m1.336     | \u001b[30m0.3865    | \u001b[30m30.04     |\n",
      "| \u001b[30m3         | \u001b[30m-2.367    | \u001b[30m1.939     | \u001b[30m2.886     | \u001b[30m65.53     |\n",
      "| \u001b[30m4         | \u001b[30m-16.24    | \u001b[30m0.2011    | \u001b[30m1.478     | \u001b[30m86.85     |\n",
      "| \u001b[30m5         | \u001b[30m-85.13    | \u001b[30m0.6546    | \u001b[30m2.504     | \u001b[30m44.79     |\n",
      "| \u001b[30m6         | \u001b[30m-11.5     | \u001b[30m0.1336    | \u001b[30m3.0       | \u001b[30m54.47     |\n",
      "| \u001b[30m7         | \u001b[30m-163.2    | \u001b[30m0.001     | \u001b[30m0.001     | \u001b[30m104.6     |\n",
      "| \u001b[30m8         | \u001b[30m-21.44    | \u001b[30m3.0       | \u001b[30m3.0       | \u001b[30m76.35     |\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 302. MiB for an array with shape (197756, 200) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m optimization_results \u001b[38;5;241m=\u001b[39m [optimize_models_mn(train_data\u001b[38;5;241m=\u001b[39mtrain_data, number_synthetic_datasets\u001b[38;5;241m=\u001b[39mnsd, number_gmm_initializations\u001b[38;5;241m=\u001b[39mngi, random_state\u001b[38;5;241m=\u001b[39mr) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m random_states]\n",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m optimization_results \u001b[38;5;241m=\u001b[39m [optimize_models_mn(train_data\u001b[38;5;241m=\u001b[39mtrain_data, number_synthetic_datasets\u001b[38;5;241m=\u001b[39mnsd, number_gmm_initializations\u001b[38;5;241m=\u001b[39mngi, random_state\u001b[38;5;241m=\u001b[39mr) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m random_states]\n",
      "Cell \u001b[1;32mIn[5], line 27\u001b[0m, in \u001b[0;36moptimize_models_mn\u001b[1;34m(train_data, number_synthetic_datasets, number_gmm_initializations, random_state)\u001b[0m\n\u001b[0;32m     17\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[0;32m     18\u001b[0m     f\u001b[38;5;241m=\u001b[39mevaluate_models,\n\u001b[0;32m     19\u001b[0m     pbounds\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     },\n\u001b[0;32m     24\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m     26\u001b[0m utility \u001b[38;5;241m=\u001b[39m UtilityFunction(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mei\u001b[39m\u001b[38;5;124m\"\u001b[39m, xi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-02\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mmaximize(init_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, acquisition_function\u001b[38;5;241m=\u001b[39mutility)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Result: \u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mmax, optimizer\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\bayes_opt\\bayesian_optimization.py:374\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    372\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[0;32m    373\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\bayes_opt\\bayesian_optimization.py:245\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mprobe(params)\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\bayes_opt\\target_space.py:364\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[_hashable(x\u001b[38;5;241m.\u001b[39mravel())]\n\u001b[0;32m    363\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys, x))\n\u001b[1;32m--> 364\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m, in \u001b[0;36moptimize_models_mn.<locals>.evaluate_models\u001b[1;34m(num_components_, C_non_white_, C_sex_)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_models\u001b[39m(num_components_, C_non_white_, C_sex_):\n\u001b[1;32m----> 8\u001b[0m     pmse_ratios, _, _ \u001b[38;5;241m=\u001b[39m train_models_mn(train_data\u001b[38;5;241m=\u001b[39mtrain_data,\n\u001b[0;32m      9\u001b[0m                                         number_synthetic_datasets\u001b[38;5;241m=\u001b[39mnumber_synthetic_datasets,\n\u001b[0;32m     10\u001b[0m                                         number_gmm_initializations\u001b[38;5;241m=\u001b[39mnumber_gmm_initializations,\n\u001b[0;32m     11\u001b[0m                                         num_components_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(num_components_),\n\u001b[0;32m     12\u001b[0m                                         C_non_white_\u001b[38;5;241m=\u001b[39mC_non_white_,\n\u001b[0;32m     13\u001b[0m                                         C_sex_\u001b[38;5;241m=\u001b[39mC_sex_)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m ((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(pmse_ratios))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m, in \u001b[0;36mtrain_models_mn\u001b[1;34m(train_data, number_synthetic_datasets, number_gmm_initializations, num_components_, C_non_white_, C_sex_)\u001b[0m\n\u001b[0;32m     11\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m########## Code for GMM ############\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# fit GMM model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m GMM \u001b[38;5;241m=\u001b[39m GaussianMixture(num_components_, n_init\u001b[38;5;241m=\u001b[39mnumber_gmm_initializations, init_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-means++\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mrng)\u001b[38;5;241m.\u001b[39mfit(train_data\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincwage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myears_of_educ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpotential_experience\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# list for synthetic datasets\u001b[39;00m\n\u001b[0;32m     19\u001b[0m sXs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\mixture\\_base.py:186\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03mThe method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m    The fitted mixture.\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# parameters are validated in fit_predict\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_predict(X, y)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\mixture\\_base.py:252\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    250\u001b[0m     prev_lower_bound \u001b[38;5;241m=\u001b[39m lower_bound\n\u001b[1;32m--> 252\u001b[0m     log_prob_norm, log_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e_step(X)\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_m_step(X, log_resp)\n\u001b[0;32m    254\u001b[0m     lower_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_lower_bound(log_resp, log_prob_norm)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\mixture\\_base.py:309\u001b[0m, in \u001b[0;36mBaseMixture._e_step\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_e_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    294\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"E step.\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m        the point of each sample in X.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m     log_prob_norm, log_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_log_prob_resp(X)\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(log_prob_norm), log_resp\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\mixture\\_base.py:529\u001b[0m, in \u001b[0;36mBaseMixture._estimate_log_prob_resp\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_estimate_log_prob_resp\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    511\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate log probabilities and responsibilities for each sample.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m    Compute the log probabilities, weighted log probabilities per\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m        logarithm of the responsibilities\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 529\u001b[0m     weighted_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_weighted_log_prob(X)\n\u001b[0;32m    530\u001b[0m     log_prob_norm \u001b[38;5;241m=\u001b[39m logsumexp(weighted_log_prob, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;66;03m# ignore underflow\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\mixture\\_base.py:482\u001b[0m, in \u001b[0;36mBaseMixture._estimate_weighted_log_prob\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_estimate_weighted_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    472\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate the weighted log-probabilities, log P(X | Z) + log weights.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;124;03m    weighted_log_prob : array, shape (n_samples, n_component)\u001b[39;00m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_log_prob(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_log_weights()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:762\u001b[0m, in \u001b[0;36mGaussianMixture._estimate_log_prob\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_estimate_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m--> 762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _estimate_log_gaussian_prob(\n\u001b[0;32m    763\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecisions_cholesky_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_type\n\u001b[0;32m    764\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:454\u001b[0m, in \u001b[0;36m_estimate_log_gaussian_prob\u001b[1;34m(X, means, precisions_chol, covariance_type)\u001b[0m\n\u001b[0;32m    447\u001b[0m     log_prob \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    448\u001b[0m         np\u001b[38;5;241m.\u001b[39msum(means\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m precisions\n\u001b[0;32m    449\u001b[0m         \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X, means\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m precisions)\n\u001b[0;32m    450\u001b[0m         \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(row_norms(X, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), precisions)\n\u001b[0;32m    451\u001b[0m     )\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# Since we are using the precision of the Cholesky decomposition,\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# `- 0.5 * log_det_precision` becomes `+ log_det_precision_chol`\u001b[39;00m\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (n_features \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi) \u001b[38;5;241m+\u001b[39m log_prob) \u001b[38;5;241m+\u001b[39m log_det\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 302. MiB for an array with shape (197756, 200) and data type float64"
     ]
    }
   ],
   "source": [
    "optimization_results = [optimize_models_mn(train_data=train_data, number_synthetic_datasets=nsd, number_gmm_initializations=ngi, random_state=r) for r in random_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_targets = [np.minimum.accumulate(-i[1].space.target) for i in optimization_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4225965",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(run_targets[0])\n",
    "plt.scatter(np.arange(len(run_targets[0])), run_targets[0], s=6)\n",
    "plt.plot(run_targets[1])\n",
    "plt.scatter(np.arange(len(run_targets[1])), run_targets[1], s=6)\n",
    "plt.title(\"Running Minimum Objective Value for MNL Synthesis\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Minimum Objective Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34094ad9",
   "metadata": {},
   "source": [
    "Choose the params that gave the best objective value across all random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eccd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = optimization_results[np.argmax([x[0]['target'] for x in optimization_results])][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab5ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1e3fa",
   "metadata": {},
   "source": [
    "Generate 20 synthetic data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff6e28-1c59-4fd4-b5cf-3dc3df54d9d6",
   "metadata": {},
   "source": [
    "On occassion, the synthesis models will produce a significantly different fit than what was observed during the optimization process. In these cases, retrain the models until a fit (judged by the pMSE ratio) consistent with the optimization results is observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643fb518",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmse_ratios, full_sXs, GMM = train_models_mn(train_data=train_data,\n",
    "                                             number_synthetic_datasets=20,\n",
    "                                             # hyperparameters for GMM\n",
    "                                             number_gmm_initializations=ngi,\n",
    "                                             num_components_=int(best_params['params']['num_components_']),\n",
    "                                             # hyperparameters for CART, end with underscore means Bayesian optimization will choose\n",
    "                                             C_non_white_=best_params['params']['C_non_white_'],\n",
    "                                             C_sex_=best_params['params']['C_sex_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pmse_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.violinplot(pmse_ratios)\n",
    "plt.xlabel(\"Density\")\n",
    "plt.ylabel(\"pMSE Ratio\")\n",
    "plt.title(\"Distribution of pMSE Ratios\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c4b464",
   "metadata": {},
   "source": [
    "# Save the synthetic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5696e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sX in enumerate(full_sXs):\n",
    "    sX.to_csv(\"../Data/IPUMS/Synthetic Datasets/gmm_and_mnl_\" + str(i) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba0c55-d4d2-4407-b062-8c4e89391604",
   "metadata": {},
   "source": [
    "Save the GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc782726-88a6-4970-90ee-fa2d1d90dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save\n",
    "with open('../Results/IPUMS/Models/gmm_and_mnl.pkl','wb') as f:\n",
    "    pickle.dump(GMM,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7eb3c-a193-43af-8c68-7485e26ea9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open('../Results/IPUMS/Models/gmm_and_mnl.pkl', 'rb') as f:\n",
    "    GMM = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cacd36",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72119d1-651c-44f6-8aa8-ebb78ead1612",
   "metadata": {},
   "source": [
    "Now apply the attribute disclosure prevention algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd4886-7e27-4dd4-8bc1-b233005739a4",
   "metadata": {},
   "source": [
    "We don't have a great baseline for the probability of being non-white, so we'll just use the proportion from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c6af3f-3cab-4e33-a560-f46912830014",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = np.mean(train_data.non_white == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba110f-a281-48dd-8cec-11a655c608d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e178a0d7-d1c7-4614-b3e5-c28c22a05fe8",
   "metadata": {},
   "source": [
    "For our threshold, we select $c = 10$, i.e., we are allowing for a 10x increase in the probability of an adversary inferring the non-white status based on the synthetic data. This is a relatively large increase. For example, this means going from XXX under the prior to no more than XXX under the updated probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa7a9b2-b85f-4ea2-91af-bb1abe52c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9af607-7813-4bb1-bccc-b206b0751f93",
   "metadata": {},
   "source": [
    "We provide a range of $\\delta$ values over which to evaluate and prevent attribute disclosure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7c9cd-af8c-4046-8439-9010becd8f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = np.linspace(0.001, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2b9e2-755c-449c-befd-a73a9ece72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_sXs = [attribute_disclosure_reduction(original_data=train_data, \n",
    "                                         synthetic_data=X,\n",
    "                                         continuous_vars=['incwage', 'years_of_educ', 'potential_experience'],\n",
    "                                         categorical_vars=['sex'],\n",
    "                                         sensitive_var='non_white',\n",
    "                                         mixture_model=GMM,\n",
    "                                         deltas=deltas, \n",
    "                                         c=c, \n",
    "                                         prior_prob=prior) for X in full_sXs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e441d9-7ac5-43b7-8366-9e01069471eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sX in enumerate(ad_sXs):\n",
    "    sX.to_csv(\"../Data/IPUMS/Synthetic Datasets/ad_gmm_and_mnl_\" + str(i) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9e7c5f-02be-4fa9-be5d-94f600d48c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
